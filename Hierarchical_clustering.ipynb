{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hierarchical clustering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNndqNb2y5wzbcwoPnayEsX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taedriel/ZSL-v2/blob/wordEmbedding/Hierarchical_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install orange3 python-louvain networkx dendropy --quiet --upgrade"
      ],
      "metadata": {
        "id": "-nHn1AH78gzp",
        "outputId": "526a28f6-fca8-4d8a-aeaa-b5963aa2f505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 29.0 MB 41.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.2 MB 49.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 253 kB 53.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 355 kB 43.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 496 kB 62.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 992 kB 43.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 230 kB 41.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 52.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 149 kB 45.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 59.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 54.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59.9 MB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 344 kB 52.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67.5 MB 81 kB/s \n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 50.0 MB/s \n",
            "\u001b[?25h  Building wheel for dendropy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for serverfiles (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import community.community_louvain as community\n",
        "import dendropy\n",
        "# if import error, launch import a second time, and it will be fine\n",
        "from Orange.clustering.hierarchical import Tree, ClusterData, SingletonData, dist_matrix_linkage, tree_from_linkage, data_clustering, leaves, WEIGHTED, dist_matrix_clustering\n",
        "from Orange.data import Table, Domain\n",
        "from Orange.distance.distance import Cosine\n",
        "from Orange.widgets.unsupervised.owhierarchicalclustering import clusters_at_height\n",
        "from Orange.misc.distmatrix import DistMatrix\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from Orange.data.variable import StringVariable"
      ],
      "metadata": {
        "id": "HSkbQhDIG0Et"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsLoader:\n",
        "\n",
        "    \"\"\"class that load an embeddings file to perform operation on it. Base class\n",
        "     for multiple operations such as matrix similarity operations.\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, filename : str):\n",
        "\n",
        "        self.file = filename\n",
        "        self.embeddings = {}\n",
        "\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            with open(self.file, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "                \n",
        "            for line in lines[1:]:\n",
        "                data = line.split(\",\")\n",
        "                self.embeddings[data[0]] = torch.FloatTensor(list(map(float, data[1:])))\n",
        "\n",
        "        except IOError as e:\n",
        "            raise IOError(f\"No file {self.file}\")\n"
      ],
      "metadata": {
        "id": "F9r4YQQI9kpr"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Solver"
      ],
      "metadata": {
        "id": "6a4--t_QLVl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLUSTER_THRESOLD = 0.85\n",
        "GROUP_BY = \"first superclass\"\n",
        "MYSTERY = \"TOGUESS\"\n",
        "SIM_THRESOLD = 0.3\n",
        "\n",
        "def left_join(complete_table, supp_info_table, key: str = \"embeddings\") -> Table:\n",
        "    \"\"\"add all <b> metas </b> column from supp_info_table to complete_table using key as joint\n",
        "    \"\"\"\n",
        "    assert key in list(map(lambda x : x.name, supp_info_table.domain.metas)), \"embeddings name not present in additional data\"\n",
        "    # assert len(complete_table) == len(supp_info_table), \"table don't contain the same number of line\"\n",
        "    print(len(complete_table), len(supp_info_table))\n",
        "    name_supp_data = [i.name for i in chain(supp_info_table.domain.metas, \n",
        "                                            supp_info_table.domain.variables, \n",
        "                                            supp_info_table.attributes) if i.name != key]\n",
        "                                            \n",
        "    supp_list_list = [[] for i in range(len(name_supp_data))]\n",
        "\n",
        "    for s in complete_table:\n",
        "        done = False\n",
        "        for d in supp_info_table:\n",
        "            if s[key] == d[key]:\n",
        "                for i, name in enumerate(name_supp_data):\n",
        "                    supp_list_list[i].append(d[name])\n",
        "                done = True\n",
        "                break\n",
        "        if not done:\n",
        "            for i, name in enumerate(name_supp_data):\n",
        "                supp_list_list[i].append(\"?\")\n",
        "\n",
        "    for i, name in enumerate(name_supp_data):\n",
        "        # print(f\"adding {name}\")\n",
        "        complete_table = complete_table.add_column(StringVariable(name), supp_list_list[i])\n",
        "\n",
        "    return complete_table\n",
        "\n",
        "def parent_of_mystery(cluster, mystery_index):\n",
        "    res = None\n",
        "    for branch in cluster.branches:\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                return cluster\n",
        "        else: \n",
        "            res = parent_of_mystery(branch, mystery_index)\n",
        "            if res is not None:\n",
        "                return res\n",
        "    \n",
        "def first_child(root):\n",
        "    if root.is_leaf:\n",
        "        return root\n",
        "    else:\n",
        "        return first_child(root.branches[0])\n",
        "\n",
        "\n",
        "def closest_to(cluster, mystery_index):\n",
        "    if len(cluster.branches) == 1:\n",
        "        return None\n",
        "\n",
        "    next = False\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        if next:\n",
        "            return first_child(branch)\n",
        "\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                if i == 0:\n",
        "                    next = True\n",
        "                else:\n",
        "                    return first_child(cluster.branches[i-1])\n",
        "\n",
        "def add_to_list(cluster, list_to_add_to):\n",
        "    \"\"\" decompose a cluster tree by adding the index of all children in the list\n",
        "    \"\"\"\n",
        "    if cluster.is_leaf:\n",
        "        list_to_add_to.append(cluster.value.index)\n",
        "\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        add_to_list(branch, list_to_add_to)\n",
        "\n",
        "def compute(lst):\n",
        "    # return max(lst,key=lst.count)\n",
        "    counter = Counter(lst)\n",
        "    return counter.most_common(len(lst))\n",
        "\n",
        "def Orange_tree_to_newick(root):\n",
        "\n",
        "    if root.is_leaf:\n",
        "        return str(root.value.index)  +  \":\" + str(root.value.height)\n",
        "\n",
        "    concat = \"(\"\n",
        "    for branch in root.branches:\n",
        "\n",
        "        concat += Orange_tree_to_newick(branch) + \",\"\n",
        "\n",
        "    concat = concat[:-1] + \")\" +  \":\" + str(root.value.height)\n",
        "    return concat\n",
        "\n",
        "def newick_to_Orange_tree(path):\n",
        "\n",
        "    return dist_matrix_clustering(DistMatrix.from_file(path), linkage=WEIGHTED)\n",
        "    \n",
        "def reroot_tree(tree, void_index):\n",
        "\n",
        "\n",
        "    newick_tree = Orange_tree_to_newick(tree) + ';'\n",
        "    \n",
        "    dendro_tree = dendropy.Tree.get_from_string(newick_tree, \"newick\", rooting=\"force-unrooted\")\n",
        "    \n",
        "    outgroup_node = dendro_tree.find_node_with_taxon_label(str(void_index))\n",
        "    print(outgroup_node)\n",
        "    dendro_tree.to_outgroup_position(outgroup_node, update_bipartitions=False)\n",
        "    dendro_tree.calc_node_root_distances()\n",
        "\n",
        "    path = \"./rerooted_tree.mat\"\n",
        "    dendro_tree.phylogenetic_distance_matrix().write_csv(path)\n",
        "    \n",
        "\n",
        "    return newick_to_Orange_tree(path)\n",
        "\n",
        "\n",
        "def clusterize(table : Table, thresold, key = \"embeddings\") -> Table:\n",
        "    \"\"\"clusterize a Oranga Table based on the height of THRESOLD\n",
        "    \"\"\"\n",
        "    null = Table.from_numpy(table.domain, [np.array([1 for i in range(len(table.domain.attributes))])], Y = None, metas = np.char.asarray([[\"NULL\", \"?\", \"?\"]]))\n",
        "    table = Table.concatenate([table, null])\n",
        "\n",
        "    for i in table[-1::-1]:\n",
        "        if i[key] == MYSTERY:\n",
        "            mystery_index = table.index(i)\n",
        "            break\n",
        "    for i in table[-1::-1]:\n",
        "        if i[key] == \"NULL\":\n",
        "            void_index = table.index(i)\n",
        "            break\n",
        "\n",
        "    root = data_clustering(table, distance=Cosine, linkage=WEIGHTED)\n",
        "    root = reroot_tree(root, void_index)\n",
        "    parent_cluster = parent_of_mystery(root, mystery_index)\n",
        "    if thresold is None:\n",
        "        thresold = min(parent_cluster.value.height + 0.05, 1)\n",
        "\n",
        "    cluster_tree = clusters_at_height(root, thresold)\n",
        "\n",
        "    list_cluster = {}\n",
        "    closest = None\n",
        "    mystery_len_cluster = -1\n",
        "    for i, cluster in enumerate(cluster_tree):\n",
        "        cluster_name     = 'C' + str(i) \n",
        "\n",
        "        current = []\n",
        "        add_to_list(cluster, current)\n",
        "        if mystery_index in current: \n",
        "            mystery_len_cluster = len(current)\n",
        "            closest = closest_to(parent_cluster, mystery_index)\n",
        "\n",
        "        for item_index in current:\n",
        "            list_cluster[item_index] = cluster_name\n",
        "        # print(cluster_name, list(map(lambda x: table[x][\"embeddings\"].value, current)))\n",
        "\n",
        "    # print(f\"last cluster: {i} ({mystery_len_cluster})\")\n",
        "    table = table.add_column(StringVariable(\"Cluster\"), [list_cluster[i] for i in range(len(table))])\n",
        "\n",
        "    return table, closest.value.index, thresold, i\n",
        "\n",
        "def one_pass(table, toguess_table, keep_cluster_line : bool = False, cluster_thresold : float = CLUSTER_THRESOLD, sim_thresold : float = SIM_THRESOLD):\n",
        "    assert GROUP_BY in list(map(lambda x: x.name, chain(table.domain.metas, \n",
        "                                                        table.domain.variables, \n",
        "                                                        table.domain.attributes))), \"Group by not in the Table !\"\n",
        "    supp_data = {\n",
        "        \"sim_thresold\"       : sim_thresold,\n",
        "        \"keep_cluster_line\"  : keep_cluster_line,\n",
        "    }\n",
        "\n",
        "    supp_data[\"format_at_beginning\"] = (len(table), \"x\", len(table.domain.attributes))\n",
        "    table, closest, thresold, nb_cluster = clusterize(table, cluster_thresold)\n",
        "    supp_data[\"cluster_thresold\"]    = thresold\n",
        "    supp_data[\"closest_to_myster\"]   = table[closest][\"embeddings\"].value if closest is not True else None,\n",
        "    supp_data[\"number_of_cluster\"]   = nb_cluster\n",
        "    #===========================================================================\n",
        "    # Cluster split\n",
        "    toguess_cluster = [d[\"Cluster\"] for d in table if d[\"embeddings\"] == MYSTERY][0]\n",
        "\n",
        "    in_cluster_table  = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value == toguess_cluster])\n",
        "    out_cluster_table = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value != toguess_cluster])\n",
        "    #===========================================================================\n",
        "    # Group by computation\n",
        "    supp_data[\"cluster_size\"] = len(in_cluster_table)\n",
        "    if len(in_cluster_table) <= 1: return [], supp_data\n",
        "    \n",
        "    main_superclass_count_list = compute([row[GROUP_BY].value for row in in_cluster_table])\n",
        "    #equality case with \"?\", take the second\n",
        "    ind = 1 if main_superclass_count_list[0][0] == \"?\" and len(main_superclass_count_list) > 1 else 0\n",
        "    main_superclass = main_superclass_count_list[ind][0]\n",
        "    supp_data[\"cluster_name\"] = main_superclass\n",
        "\n",
        "    nb_dimension = len(list(in_cluster_table.domain.attributes))\n",
        "    average_cluster = Table.from_list(in_cluster_table.domain, [\n",
        "        [sum([line[i] for line in in_cluster_table]) / nb_dimension  for i in in_cluster_table.domain.attributes] + [\"cluster_average\"]\n",
        "    ])\n",
        "\n",
        "    # main_superclass_table = Table.from_list(superclass_embeddings.domain, [i for i in superclass_embeddings if i[\"embeddings\"] == main_superclass])\n",
        "    main_superclass_table = Table.concatenate([in_cluster_table, Table.from_table(in_cluster_table.domain, average_cluster)])\n",
        "    #===========================================================================\n",
        "    # thresold computation\n",
        "    to_copy_row_instance = [d for d in main_superclass_table if d[\"embeddings\"] == MYSTERY][0]\n",
        "    to_copy = list(to_copy_row_instance.attributes())\n",
        "\n",
        "    to_compare_row_instance = [d for d in main_superclass_table if d[\"Cluster\"] == \"?\"][0]\n",
        "    to_compare = list(to_compare_row_instance.attributes())\n",
        "\n",
        "    dead_row = [k for k, (i, j) in enumerate(zip(to_copy, to_compare)) if abs(i - j) <= sim_thresold]\n",
        "    supp_data[\"removed_col\"] = len(dead_row) \n",
        "    #===========================================================================\n",
        "    # reconstruct the table filtering dead row and cluster. Remove used cluster row if \n",
        "    # keep_cluster_line is set to False\n",
        "    new_domain = Domain(attributes = [i for i in out_cluster_table.domain.attributes if int(i.name) not in dead_row], \n",
        "                        metas      = [i for i in out_cluster_table.domain.metas if i.name != \"Cluster\"])\n",
        "\n",
        "    # do the same on the data\n",
        "    data_attr, data_meta = [], []\n",
        "    whole_data = list(out_cluster_table) + list(toguess_table)\n",
        "    if keep_cluster_line: whole_data += list(in_cluster_table)\n",
        "\n",
        "    for rowinstance in whole_data:\n",
        "        data_attr.append([rowinstance[k] for k, i in enumerate(out_cluster_table.domain.attributes) if int(i.name) not in dead_row])\n",
        "        data_meta.append([rowinstance.metas[k] for k, i in enumerate(out_cluster_table.domain.metas) if i.name != \"Cluster\"])\n",
        "\n",
        "    return Table.from_numpy(new_domain, X = data_attr, metas = data_meta), supp_data\n",
        "\n",
        "\n",
        "def standardize_first(table):\n",
        "    values = table[0]\n",
        "    mean = np.mean(values)\n",
        "    std  = np.std(values)\n",
        "\n",
        "    for v in range(len(values)):\n",
        "        values[v] = (values[v] - mean) / std\n",
        "\n",
        "    return Table.from_numpy(table.domain, [values], None, table.metas)"
      ],
      "metadata": {
        "id": "nPhqx45tbDSE"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mystery(complete_table, mystery, cluster_thresold_lambda, sim_thresold_lambda):\n",
        "\n",
        "    toguess_table = Table.from_numpy(complete_table.domain, [np.array(mystery)], Y = None, metas = np.char.asarray([[MYSTERY, \"?\", \"?\"]]))\n",
        "    # toguess_table = standardize_first(toguess_table)\n",
        "\n",
        "    table = Table.concatenate([complete_table, toguess_table])\n",
        "    old_table = table\n",
        "\n",
        "    advancement = []\n",
        "    for i in range(5):\n",
        "        old_table = table\n",
        "        table, data = one_pass(table, toguess_table,\n",
        "                                      keep_cluster_line = False, \n",
        "                                      cluster_thresold  = cluster_thresold_lambda(i), \n",
        "                                      sim_thresold      = sim_thresold_lambda(i))\n",
        "        advancement.append(data)\n",
        "\n",
        "        if len(table) <= 1 or data[\"cluster_size\"] < 10:\n",
        "            break\n",
        "    return advancement\n",
        "\n",
        "            # print(\"no result, trying to upper cluster thresold\")\n",
        "            # current_cluster_thresold = 0.55 + 0.05\n",
        "            # while current_cluster_thresold < 1 and len(current_table) == 0:\n",
        "            #     current_table, data = one_pass(old_table, keep_cluster_line = False, cluster_thresold = current_cluster_thresold, sim_thresold = 0.3 + 0.05 * i)\n",
        "            #     print(data)\n",
        "            #     current_cluster_thresold += 0.05\n",
        "            # if len(current_table) == 0:\n",
        "            #     print(\"no suitable thresold...\")\n",
        "            #     break\n",
        "            # print(\"find a suitable thresold, resuming\")"
      ],
      "metadata": {
        "id": "BnjjnjQuFJxe"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generic_table = Table(\"/content/ZSL-v2/ressources/Ayoub-average.csv\")\n",
        "supp_info_table = Table(\"/content/class_map_imagenet.csv\")\n",
        "generic_table = left_join(generic_table, supp_info_table)\n",
        "\n",
        "print(len(generic_table))\n",
        "\n",
        "# superclass_embeddings = Table(\"/content/custom-wikipedia2vec-300_superclass.csv\")"
      ],
      "metadata": {
        "id": "g_uIdCXyw6tS",
        "outputId": "619860b1-fa8c-45ea-98bd-cdaec3e9433b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "996 999\n",
            "996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myster_file = EmbeddingsLoader(\"/content/mystery.csv\")"
      ],
      "metadata": {
        "id": "nnW8xIgJThWR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_result(list_dict):\n",
        "    superclass_list = []\n",
        "    for dic in list_dict:\n",
        "        if type(dic) == type(dict()) and \"cluster_name\" in dic.keys():\n",
        "            superclass_list.append(f\"{dic['cluster_name']}({dic['closest_to_myster']})\")\n",
        "    \n",
        "    return superclass_list\n",
        "\n",
        "# cluster_thresold_lambda = lambda x : 0.30 + 0.20 * x\n",
        "cluster_thresold_lambda     = lambda x : None\n",
        "sim_thresold_lambda     = lambda x : 0.3\n",
        "\n",
        "for i, embeddings in myster_file.embeddings.items():\n",
        "\n",
        "    result = solve_mystery(generic_table, embeddings, cluster_thresold_lambda, sim_thresold_lambda)\n",
        "    print(f\"{i}\\t{' + '.join(format_result(result)): <80}\\t\\t{result}\")\n"
      ],
      "metadata": {
        "id": "AgI9x2O0Pkv4",
        "outputId": "8584607a-c19e-4d30-8440-aa5a5785153a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Node object at 0x7fd525528410: 'None' (<Taxon 0x7fd525528790 '997'>)>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-157-f5016e4f29f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyster_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_mystery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_thresold_lambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_thresold_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{i}\\t{' + '.join(format_result(result)): <80}\\t\\t{result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-156-7447fda7a3d7>\u001b[0m in \u001b[0;36msolve_mystery\u001b[0;34m(complete_table, mystery, cluster_thresold_lambda, sim_thresold_lambda)\u001b[0m\n\u001b[1;32m     13\u001b[0m                                       \u001b[0mkeep_cluster_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                       \u001b[0mcluster_thresold\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcluster_thresold_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                       sim_thresold      = sim_thresold_lambda(i))\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0madvancement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-c82a1ababdbc>\u001b[0m in \u001b[0;36mone_pass\u001b[0;34m(table, toguess_table, keep_cluster_line, cluster_thresold, sim_thresold)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0msupp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"format_at_beginning\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_thresold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0msupp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cluster_thresold\"\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mthresold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0msupp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"closest_to_myster\"\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclosest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclosest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-c82a1ababdbc>\u001b[0m in \u001b[0;36mclusterize\u001b[0;34m(table, thresold, key)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCosine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWEIGHTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreroot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoid_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mparent_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_of_mystery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmystery_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mthresold\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-c82a1ababdbc>\u001b[0m in \u001b[0;36mreroot_tree\u001b[0;34m(tree, void_index)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewick_to_Orange_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-c82a1ababdbc>\u001b[0m in \u001b[0;36mnewick_to_Orange_tree\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnewick_to_Orange_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdist_matrix_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDistMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWEIGHTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreroot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoid_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/Orange/misc/distmatrix.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, filename)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distance file must begin with dimension\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0msymmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: distance file must begin with dimension"
          ]
        }
      ]
    }
  ]
}