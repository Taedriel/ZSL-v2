{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hierarchical clustering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMdkGHivrb7S2I507CnQr1H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taedriel/ZSL-v2/blob/wordEmbedding/Hierarchical_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install orange3 python-louvain networkx dendropy biopython scikit-bio --quiet --upgrade"
      ],
      "metadata": {
        "id": "-nHn1AH78gzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import community.community_louvain as community\n",
        "import dendropy\n",
        "# if import error, launch import a second time, and it will be fine\n",
        "from Orange.clustering.hierarchical import Tree, ClusterData, SingletonData, dist_matrix_linkage, tree_from_linkage, data_clustering, leaves, WEIGHTED, dist_matrix_clustering\n",
        "from Orange.data import Table, Domain\n",
        "from Orange.distance.distance import Cosine\n",
        "from Orange.widgets.unsupervised.owhierarchicalclustering import clusters_at_height\n",
        "from Orange.misc.distmatrix import DistMatrix\n",
        "from Bio import Phylo\n",
        "from io import StringIO\n",
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from Orange.data.variable import StringVariable\n",
        "from skbio import DistanceMatrix\n",
        "from skbio.tree import nj\n",
        "from typing import Dict, Tuple, List, Callable\n",
        "from tqdm import tqdm\n",
        "import sklearn.preprocessing as pp\n",
        "from scipy import sparse\n",
        "\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "HSkbQhDIG0Et"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsLoader:\n",
        "\n",
        "    \"\"\"class that load an embeddings file to perform operation on it. Base class\n",
        "     for multiple operations such as matrix similarity operations.\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, filename : str):\n",
        "\n",
        "        self.file = filename\n",
        "        self.embeddings = {}\n",
        "\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            with open(self.file, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "                \n",
        "            for line in lines[1:]:\n",
        "                data = line.split(\",\")\n",
        "                self.embeddings[data[0]] = torch.FloatTensor(list(map(float, data[1:])))\n",
        "\n",
        "        except IOError as e:\n",
        "            raise IOError(f\"No file {self.file}\")"
      ],
      "metadata": {
        "id": "F9r4YQQI9kpr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Solver"
      ],
      "metadata": {
        "id": "6a4--t_QLVl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLUSTER_THRESOLD = 0.85\n",
        "GROUP_BY = \"first superclass\"\n",
        "MYSTERY = \"TOGUESS\"\n",
        "SIM_THRESOLD = 0.3\n",
        "\n",
        "def left_join(complete_table, supp_info_table, key: str = \"embeddings\") -> Table:\n",
        "    \"\"\"add all <b> metas </b> column from supp_info_table to complete_table using key as joint\n",
        "    \"\"\"\n",
        "    assert key in list(map(lambda x : x.name, supp_info_table.domain.metas)), \"embeddings name not present in additional data\"\n",
        "    # assert len(complete_table) == len(supp_info_table), \"table don't contain the same number of line\"\n",
        "    print(len(complete_table), len(supp_info_table))\n",
        "    name_supp_data = [i.name for i in chain(supp_info_table.domain.metas, \n",
        "                                            supp_info_table.domain.variables, \n",
        "                                            supp_info_table.attributes) if i.name != key]\n",
        "                                            \n",
        "    supp_list_list = [[] for i in range(len(name_supp_data))]\n",
        "\n",
        "    for s in complete_table:\n",
        "        done = False\n",
        "        for d in supp_info_table:\n",
        "            if s[key] == d[key]:\n",
        "                for i, name in enumerate(name_supp_data):\n",
        "                    supp_list_list[i].append(d[name])\n",
        "                done = True\n",
        "                break\n",
        "        if not done:\n",
        "            for i, name in enumerate(name_supp_data):\n",
        "                supp_list_list[i].append(\"?\")\n",
        "\n",
        "    for i, name in enumerate(name_supp_data):\n",
        "        # print(f\"adding {name}\")\n",
        "        complete_table = complete_table.add_column(StringVariable(name), supp_list_list[i])\n",
        "\n",
        "    return complete_table\n",
        "\n",
        "def parent_of_mystery(cluster, mystery_index):\n",
        "    res = None\n",
        "    for branch in cluster.branches:\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                return cluster\n",
        "        else: \n",
        "            res = parent_of_mystery(branch, mystery_index)\n",
        "            if res is not None:\n",
        "                return res\n",
        "    \n",
        "def first_child(root):\n",
        "    if root.is_leaf:\n",
        "        return root\n",
        "    else:\n",
        "        return first_child(root.branches[0])\n",
        "\n",
        "\n",
        "def closest_to(cluster, mystery_index):\n",
        "    if len(cluster.branches) == 1:\n",
        "        return None\n",
        "\n",
        "    next = False\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        if next:\n",
        "            return first_child(branch)\n",
        "\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                if i == 0:\n",
        "                    next = True\n",
        "                else:\n",
        "                    return first_child(cluster.branches[i-1])\n",
        "\n",
        "def add_to_list(cluster, list_to_add_to):\n",
        "    \"\"\" decompose a cluster tree by adding the index of all children in the list\n",
        "    \"\"\"\n",
        "    if cluster.is_leaf:\n",
        "        list_to_add_to.append(cluster.value.index)\n",
        "\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        add_to_list(branch, list_to_add_to)\n",
        "\n",
        "def compute(lst, tips):\n",
        "    # return max(lst,key=lst.count)\n",
        "    weighted_lst = {elem: 0 for elem in set(lst)}\n",
        "    for elem in lst:\n",
        "        if elem in tips:\n",
        "            weighted_lst[elem] += 3\n",
        "        else:\n",
        "            weighted_lst[elem] += 1\n",
        "\n",
        "    most_common = sorted([(key, elem) for key, elem in weighted_lst.items()], key = lambda x : x[1], reverse = True)\n",
        "    # print(most_common)\n",
        "    return most_common\n",
        "\n",
        "def Orange_tree_to_newick(root):\n",
        "\n",
        "    if root.is_leaf:\n",
        "        return str(root.value.index)  +  \":\" + str(root.value.height)\n",
        "\n",
        "    concat = \"(\"\n",
        "    for branch in root.branches:\n",
        "\n",
        "        concat += Orange_tree_to_newick(branch) + \",\"\n",
        "\n",
        "    concat = concat[:-1] + \")\" +  \":\" + str(root.value.height)\n",
        "    return concat\n",
        "\n",
        "def biotree_to_Orange_tree(tree):\n",
        "    def recur_parse(root, acc, depth):\n",
        "        if root.is_terminal():\n",
        "            val = root.name\n",
        "            leaf = Tree(SingletonData(range = range(len(acc), len(acc)+1), \n",
        "                                 height= 0.0, \n",
        "                                 index = val), ())\n",
        "            acc.append(leaf)\n",
        "            return leaf\n",
        "\n",
        "        else:\n",
        "            list_cla = []\n",
        "            for cla in root:\n",
        "                sub_tree = recur_parse(cla, acc, depth + (root.branch_length or 0))\n",
        "                list_cla.append(sub_tree)\n",
        "            node = Tree(ClusterData(range = range(list_cla[0]._Tree__value.range.start, list_cla[-1]._Tree__value.range.stop),\n",
        "                               height = root.branch_length or 0), tuple(list_cla))\n",
        "            return node\n",
        "\n",
        "    orange_tree = recur_parse(tree.root, [], 0)\n",
        "    return orange_tree\n",
        "\n",
        "def reroot_tree(tree, void_index, format):\n",
        "    newick_tree = Orange_tree_to_newick(tree)\n",
        "    tree = Phylo.read(StringIO(newick_tree), \"newick\")\n",
        "    tree.root_with_outgroup(tree.root.find_clades(\"NULL\"))\n",
        "\n",
        "    return biotree_to_Orange_tree(tree)\n",
        "\n",
        "def sim2dist(mat : List[List[float]], func : Callable[[float], float] \\\n",
        "             = lambda x: 1 - x, hollow : bool = True) -> List[List[float]]:\n",
        "    \"\"\" map the function func to each elements in the matrix\n",
        "\n",
        "    apply the lambda function func to each element of the matrix. if hollow is set \n",
        "    to True, set the diagonal of the matrix to 0.\n",
        "    Args:\n",
        "        mat (List[List[float]]) : a matrix of number\n",
        "        func (Callable[[float], float]) : a simple function to apply to each elem of the matrix\n",
        "        hollow (bool) : whether to consider the diagonal of the matrix or not\n",
        "    \n",
        "    \"\"\"\n",
        "    inv_data = [[0 for i in range(len(mat[0]))] for j in range(len(mat))]\n",
        "\n",
        "    for i, elem in enumerate(mat):\n",
        "        for j, case in enumerate(elem):\n",
        "            if i == j and hollow: \n",
        "                inv_data[i][j] = 0\n",
        "            else:\n",
        "                inv_data[i][j] = func(case)\n",
        "                \n",
        "    return inv_data\n",
        "\n",
        "def njt(table, key : str):\n",
        "\n",
        "    embeddings = {}\n",
        "    for line in table:\n",
        "        embeddings[str(line[key].value)] = list(line.attributes()) \n",
        "        \n",
        "\n",
        "    ids = list(map(lambda x : x.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"'\", \"_\"), embeddings.keys()))\n",
        "    data = np.array([item for item in embeddings.values()])\n",
        "    \n",
        "    cos_A = sim2dist(1-pairwise_distances(data, metric=\"cosine\"))\n",
        "\n",
        "    def constructor(x):\n",
        "        biotree = Phylo.read( StringIO(x), \"newick\")\n",
        "        # print(biotree)\n",
        "        return biotree_to_Orange_tree(biotree)\n",
        "\n",
        "    dm = DistanceMatrix(cos_A, ids)\n",
        "    tree = nj(dm, result_constructor = constructor)\n",
        "\n",
        "    return tree\n",
        "\n",
        "\n",
        "\n",
        "def clusterize(table : Table, thresold, key = \"embeddings\") -> Table:\n",
        "    \"\"\"clusterize a Oranga Table based on the height of THRESOLD\n",
        "    \"\"\"\n",
        "    null = Table.from_numpy(table.domain, [np.array([1 for i in range(len(table.domain.attributes))])], Y = None, metas = np.char.asarray([[\"NULL\", \"?\", \"?\"]]))\n",
        "    table = Table.concatenate([table, null])\n",
        "\n",
        "    for i in table[-1::-1]:\n",
        "        if i[key] == MYSTERY:\n",
        "            mystery_index = table.index(i)\n",
        "            break\n",
        "    for i in table[-1::-1]:\n",
        "        if i[key] == \"NULL\":\n",
        "            void_index = table.index(i)\n",
        "            break\n",
        "\n",
        "    # root = data_clustering(table, distance=Cosine, linkage=WEIGHTED)\n",
        "    root = njt(table, key)\n",
        "    root = reroot_tree(root, void_index, (len(table[0])))\n",
        "\n",
        "    parent_cluster = parent_of_mystery(root, MYSTERY)\n",
        "    if thresold is None:\n",
        "        thresold = min(parent_cluster.value.height + 0.05, 1)\n",
        "\n",
        "    cluster_tree = clusters_at_height(root, thresold)\n",
        "\n",
        "    list_cluster = {}\n",
        "    closest = None\n",
        "    mystery_len_cluster = -1\n",
        "    for i, cluster in enumerate(cluster_tree):\n",
        "        cluster_name     = 'C' + str(i) \n",
        "\n",
        "        current = []\n",
        "        add_to_list(cluster, current)\n",
        "        if MYSTERY in current: \n",
        "            mystery_len_cluster = len(current)\n",
        "            closest = closest_to(parent_cluster, MYSTERY)\n",
        "\n",
        "        for item_index in current:\n",
        "            list_cluster[item_index] = cluster_name\n",
        "        # print(cluster_name, list(map(lambda x: table[x][\"embeddings\"].value, current)))\n",
        "\n",
        "    table = table.add_column(StringVariable(\"Cluster\"), [i for i in list_cluster])\n",
        "\n",
        "    print(closest.value.index)\n",
        "\n",
        "    return table, closest.value.index, thresold, i\n",
        "\n",
        "from typing import List\n",
        "def one_pass(table, toguess_table, keep_cluster_line : bool = False, cluster_thresold : float = CLUSTER_THRESOLD, sim_thresold : float = SIM_THRESOLD, tips : List[str] = []):\n",
        "    assert GROUP_BY in list(map(lambda x: x.name, chain(table.domain.metas, \n",
        "                                                        table.domain.variables, \n",
        "                                                        table.domain.attributes))), \"Group by not in the Table !\"\n",
        "    supp_data = {\n",
        "        \"sim_thresold\"       : sim_thresold,\n",
        "        \"keep_cluster_line\"  : keep_cluster_line,\n",
        "    }\n",
        "\n",
        "    supp_data[\"format_at_beginning\"] = (len(table), \"x\", len(table.domain.attributes))\n",
        "    table, closest, thresold, nb_cluster = clusterize(table, cluster_thresold)\n",
        "    supp_data[\"cluster_thresold\"]    = thresold\n",
        "    supp_data[\"closest_to_myster\"]   = closest # table[][\"embeddings\"].value if closest is not True else None,\n",
        "    supp_data[\"number_of_cluster\"]   = nb_cluster\n",
        "    #===========================================================================\n",
        "    # Cluster split\n",
        "    toguess_cluster = [d[\"Cluster\"] for d in table if d[\"embeddings\"] == MYSTERY][0]\n",
        "\n",
        "    in_cluster_table  = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value == toguess_cluster])\n",
        "    out_cluster_table = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value != toguess_cluster])\n",
        "    #===========================================================================\n",
        "    # Group by computation\n",
        "    supp_data[\"cluster_size\"] = len(in_cluster_table)\n",
        "    if len(in_cluster_table) <= 1: return [], supp_data\n",
        "    \n",
        "    main_superclass_count_list = compute([row[GROUP_BY].value for row in in_cluster_table], tips)\n",
        "    #equality case with \"?\", take the second\n",
        "    ind = 1 if main_superclass_count_list[0][0] == \"?\" and len(main_superclass_count_list) > 1 else 0\n",
        "    main_superclass = main_superclass_count_list[ind][0]\n",
        "    supp_data[\"cluster_name\"] = main_superclass\n",
        "\n",
        "    nb_dimension = len(list(in_cluster_table.domain.attributes))\n",
        "    average_cluster = Table.from_list(in_cluster_table.domain, [\n",
        "        [sum([line[i] for line in in_cluster_table]) / nb_dimension  for i in in_cluster_table.domain.attributes] + [\"cluster_average\"]\n",
        "    ])\n",
        "\n",
        "    # main_superclass_table = Table.from_list(superclass_embeddings.domain, [i for i in superclass_embeddings if i[\"embeddings\"] == main_superclass])\n",
        "    main_superclass_table = Table.concatenate([in_cluster_table, Table.from_table(in_cluster_table.domain, average_cluster)])\n",
        "    #===========================================================================\n",
        "    # thresold computation\n",
        "    to_copy_row_instance = [d for d in main_superclass_table if d[\"embeddings\"] == MYSTERY][0]\n",
        "    to_copy = list(to_copy_row_instance.attributes())\n",
        "\n",
        "    to_compare_row_instance = [d for d in main_superclass_table if d[\"Cluster\"] == \"?\"][0]\n",
        "    to_compare = list(to_compare_row_instance.attributes())\n",
        "\n",
        "    dead_row = [k for k, (i, j) in enumerate(zip(to_copy, to_compare)) if abs(i - j) <= sim_thresold]\n",
        "    supp_data[\"removed_col\"] = len(dead_row) \n",
        "    #===========================================================================\n",
        "    # reconstruct the table filtering dead row and cluster. Remove used cluster row if \n",
        "    # keep_cluster_line is set to False\n",
        "    new_domain = Domain(attributes = [i for i in out_cluster_table.domain.attributes], # if int(i.name) not in dead_row], \n",
        "                        metas      = [i for i in out_cluster_table.domain.metas if i.name != \"Cluster\"])\n",
        "\n",
        "    # do the same on the data\n",
        "    data_attr, data_meta = [], []\n",
        "    whole_data = list(out_cluster_table) + list(toguess_table)\n",
        "    if keep_cluster_line: whole_data += list(in_cluster_table)\n",
        "\n",
        "    for rowinstance in whole_data:\n",
        "        # data_attr.append([rowinstance[k] for k, i in enumerate(out_cluster_table.domain.attributes) if int(i.name) not in dead_row])\n",
        "        data_attr.append([rowinstance[k] for k, i in enumerate(out_cluster_table.domain.attributes)])\n",
        "        data_meta.append([rowinstance.metas[k] for k, i in enumerate(out_cluster_table.domain.metas) if i.name != \"Cluster\"])\n",
        "\n",
        "\n",
        "    return Table.from_numpy(new_domain, X = data_attr, metas = data_meta), supp_data\n",
        "\n",
        "\n",
        "def standardize_first(table):\n",
        "    values = table[0]\n",
        "    mean = np.mean(values)\n",
        "    std  = np.std(values)\n",
        "\n",
        "    for v in range(len(values)):\n",
        "        values[v] = (values[v] - mean) / std\n",
        "\n",
        "    return Table.from_numpy(table.domain, [values], None, table.metas)"
      ],
      "metadata": {
        "id": "nPhqx45tbDSE"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mystery(complete_table, mystery, cluster_thresold_lambda, sim_thresold_lambda, tips):\n",
        "\n",
        "    toguess_table = Table.from_numpy(complete_table.domain, [np.array(mystery)], Y = None, metas = np.char.asarray([[MYSTERY, \"?\", \"?\"]]))\n",
        "    # toguess_table = standardize_first(toguess_table)\n",
        "\n",
        "    table = Table.concatenate([complete_table, toguess_table])\n",
        "    old_table = table\n",
        "\n",
        "    advancement = []\n",
        "    for i in range(5):\n",
        "        old_table = table\n",
        "        table, data = one_pass(table, toguess_table,\n",
        "                                      keep_cluster_line = False, \n",
        "                                      cluster_thresold  = cluster_thresold_lambda(i), \n",
        "                                      sim_thresold      = sim_thresold_lambda(i),\n",
        "                                      tips = tips)\n",
        "        advancement.append(data)\n",
        "\n",
        "        if len(table) <= 1 or data[\"cluster_size\"] < 10:\n",
        "            break\n",
        "    return advancement\n",
        "\n",
        "            # print(\"no result, trying to upper cluster thresold\")\n",
        "            # current_cluster_thresold = 0.55 + 0.05\n",
        "            # while current_cluster_thresold < 1 and len(current_table) == 0:\n",
        "            #     current_table, data = one_pass(old_table, keep_cluster_line = False, cluster_thresold = current_cluster_thresold, sim_thresold = 0.3 + 0.05 * i)\n",
        "            #     print(data)\n",
        "            #     current_cluster_thresold += 0.05\n",
        "            # if len(current_table) == 0:\n",
        "            #     print(\"no suitable thresold...\")\n",
        "            #     break\n",
        "            # print(\"find a suitable thresold, resuming\")"
      ],
      "metadata": {
        "id": "BnjjnjQuFJxe"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generic_table = Table(\"/content/ResNet50-average.csv\")\n",
        "supp_info_table = Table(\"/content/class_map_imagenet.csv\")\n",
        "generic_table = left_join(generic_table, supp_info_table)\n",
        "\n",
        "print(len(generic_table))\n",
        "\n",
        "# superclass_embeddings = Table(\"/content/custom-wikipedia2vec-300_superclass.csv\")"
      ],
      "metadata": {
        "id": "g_uIdCXyw6tS",
        "outputId": "49da6dca-3bf2-4e51-b810-eeb14198fb50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "996 999\n",
            "996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myster_file = EmbeddingsLoader(\"/content/mystery_CNN.csv\")"
      ],
      "metadata": {
        "id": "nnW8xIgJThWR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_result(list_dict):\n",
        "    superclass_list = []\n",
        "    for dic in list_dict:\n",
        "        if type(dic) == type(dict()) and \"cluster_name\" in dic.keys():\n",
        "            superclass_list.append(f\"{dic['cluster_name']}[{round(dic['cluster_size'] / len(generic_table) * 100, 1)}%]({dic['closest_to_myster'][0]})\")\n",
        "    \n",
        "    return superclass_list\n",
        "\n",
        "# cluster_thresold_lambda = lambda x : 0.30 + 0.20 * x\n",
        "cluster_thresold_lambda     = lambda x : None\n",
        "sim_thresold_lambda     = lambda x : 0.3\n",
        "\n",
        "tips = [[\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"monotreme\"],\n",
        "        [\"monotreme\"],\n",
        "        [\"monotreme\"],\n",
        "        [\"cat\"],\n",
        "        [\"rodent\"],\n",
        "        [\"dog\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"]]\n",
        "\n",
        "for k, (i, embeddings) in enumerate(myster_file.embeddings.items()):\n",
        "\n",
        "    result = solve_mystery(generic_table, embeddings, cluster_thresold_lambda, sim_thresold_lambda, tips[k])\n",
        "    print(f\"{i}\\t{' + '.join(format_result(result)): <80}\\t\\t{result}\")\n"
      ],
      "metadata": {
        "id": "AgI9x2O0Pkv4",
        "outputId": "689d5efa-888b-4ded-d842-0d014c8402b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jinrikisha\n",
            "bear1\t                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (997, 'x', 2048), 'cluster_thresold': 0.09395700000000001, 'closest_to_myster': 'jinrikisha', 'number_of_cluster': 0, 'cluster_size': 1}]\n",
            "schipperke\n",
            "bear2\t                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (997, 'x', 2048), 'cluster_thresold': 0.08696100000000001, 'closest_to_myster': 'schipperke', 'number_of_cluster': 0, 'cluster_size': 1}]\n",
            "jinrikisha\n",
            "bear3\t                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (997, 'x', 2048), 'cluster_thresold': 0.10772999999999999, 'closest_to_myster': 'jinrikisha', 'number_of_cluster': 0, 'cluster_size': 1}]\n",
            "platypus\n",
            "platypus1\t                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (997, 'x', 2048), 'cluster_thresold': 0.101873, 'closest_to_myster': 'platypus', 'number_of_cluster': 0, 'cluster_size': 1}]\n",
            "platypus\n",
            "platypus2\t                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (997, 'x', 2048), 'cluster_thresold': 0.129278, 'closest_to_myster': 'platypus', 'number_of_cluster': 0, 'cluster_size': 1}]\n",
            "platypus\n",
            "platypus3\t                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (997, 'x', 2048), 'cluster_thresold': 0.093638, 'closest_to_myster': 'platypus', 'number_of_cluster': 0, 'cluster_size': 1}]\n",
            "pool_table\n",
            "cat\t                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (997, 'x', 2048), 'cluster_thresold': 0.06728400000000001, 'closest_to_myster': 'pool_table', 'number_of_cluster': 0, 'cluster_size': 1}]\n",
            "croquet_ball\n",
            "hamster\t                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (997, 'x', 2048), 'cluster_thresold': 0.085915, 'closest_to_myster': 'croquet_ball', 'number_of_cluster': 0, 'cluster_size': 1}]\n",
            "cocker_spaniel\n",
            "dog\t                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (997, 'x', 2048), 'cluster_thresold': 0.06772800000000001, 'closest_to_myster': 'cocker_spaniel', 'number_of_cluster': 0, 'cluster_size': 1}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7YVJ5THVguaG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}