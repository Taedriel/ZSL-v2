{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hierarchical clustering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNEXHBlAJae4IxOeBNaDJW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taedriel/ZSL-v2/blob/wordEmbeddingPython/zsl/word_embeddings/notebook/Hierarchical_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install orange3 python-louvain networkx dendropy biopython scikit-bio --quiet --upgrade"
      ],
      "metadata": {
        "id": "-nHn1AH78gzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import community.community_louvain as community\n",
        "import dendropy\n",
        "# if import error, launch import a second time, and it will be fine\n",
        "from typing import Dict, Tuple, List, Callable\n",
        "from tqdm import tqdm\n",
        "from operator import attrgetter\n",
        "\n",
        "from Orange.clustering.hierarchical import Tree, ClusterData, SingletonData\n",
        "from Orange.data import Table, Domain\n",
        "from Orange.data.variable import StringVariable\n",
        "\n",
        "from Bio import Phylo\n",
        "from io import StringIO\n",
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "\n",
        "from itertools import chain\n",
        "from collections import Counter, deque\n",
        "\n",
        "from skbio import DistanceMatrix\n",
        "from skbio.tree import nj\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n"
      ],
      "metadata": {
        "id": "HSkbQhDIG0Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsLoader:\n",
        "\n",
        "    \"\"\"class that load an embeddings file to perform operation on it. Base class\n",
        "     for multiple operations such as matrix similarity operations.\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, filename : str):\n",
        "\n",
        "        self.file = filename\n",
        "        self.embeddings = {}\n",
        "\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            with open(self.file, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "                \n",
        "            for line in lines[1:]:\n",
        "                data = line.split(\",\")\n",
        "                self.embeddings[data[0]] = torch.FloatTensor(list(map(float, data[1:])))\n",
        "\n",
        "        except IOError as e:\n",
        "            raise IOError(f\"No file {self.file}\")"
      ],
      "metadata": {
        "id": "F9r4YQQI9kpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Solver"
      ],
      "metadata": {
        "id": "6a4--t_QLVl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GROUP_BY = \"first superclass\"\n",
        "MYSTERY = \"TOGUESS\"\n",
        "SIM_THRESOLD = 0.3\n",
        "\n",
        "def left_join(complete_table, supp_info_table, key: str = \"embeddings\") -> Table:\n",
        "    \"\"\"add all <b> metas </b> column from supp_info_table to complete_table using key as joint\n",
        "    \"\"\"\n",
        "    assert key in list(map(lambda x : x.name, supp_info_table.domain.metas)), \"embeddings name not present in additional data\"\n",
        "    # assert len(complete_table) == len(supp_info_table), \"table don't contain the same number of line\"\n",
        "    print(len(complete_table), len(supp_info_table))\n",
        "    name_supp_data = [i.name for i in chain(supp_info_table.domain.metas, \n",
        "                                            supp_info_table.domain.variables, \n",
        "                                            supp_info_table.attributes) if i.name != key]\n",
        "                                            \n",
        "    supp_list_list = [[] for i in range(len(name_supp_data))]\n",
        "\n",
        "    for s in complete_table:\n",
        "        done = False\n",
        "        for d in supp_info_table:\n",
        "            if s[key] == d[key]:\n",
        "                for i, name in enumerate(name_supp_data):\n",
        "                    supp_list_list[i].append(d[name])\n",
        "                done = True\n",
        "                break\n",
        "        if not done:\n",
        "            for i, name in enumerate(name_supp_data):\n",
        "                supp_list_list[i].append(\"?\")\n",
        "\n",
        "    for i, name in enumerate(name_supp_data):\n",
        "        # print(f\"adding {name}\")\n",
        "        complete_table = complete_table.add_column(StringVariable(name), supp_list_list[i])\n",
        "\n",
        "    return complete_table\n",
        "\n",
        "def parent_of_mystery(cluster):\n",
        "    res = None\n",
        "    for branch in cluster.branches:\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == MYSTERY:\n",
        "                return cluster\n",
        "        else: \n",
        "            res = parent_of_mystery(branch)\n",
        "            if res is not None:\n",
        "                return res\n",
        "    return None\n",
        "    \n",
        "def first_child(root):\n",
        "    if root.is_leaf:\n",
        "        return root\n",
        "    else:\n",
        "        return first_child(root.branches[0])\n",
        "\n",
        "\n",
        "def closest_to(cluster, mystery_index):\n",
        "    if len(cluster.branches) == 1:\n",
        "        return None\n",
        "\n",
        "    next = False\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        if next:\n",
        "            return first_child(branch)\n",
        "\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                if i == 0:\n",
        "                    next = True\n",
        "                else:\n",
        "                    return first_child(cluster.branches[i-1])\n",
        "\n",
        "def add_to_list(cluster, list_to_add_to):\n",
        "    \"\"\" decompose a cluster tree by adding the index of all children in the list\n",
        "    \"\"\"\n",
        "    if cluster.is_leaf:\n",
        "        list_to_add_to.append(cluster.value.index)\n",
        "\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        add_to_list(branch, list_to_add_to)\n",
        "\n",
        "def compute(lst, tips):\n",
        "    # return max(lst,key=lst.count)\n",
        "    weighted_lst = {elem: 0 for elem in set(lst)}\n",
        "    for elem in lst:\n",
        "        if elem in tips:\n",
        "            weighted_lst[elem] += 3\n",
        "        else:\n",
        "            weighted_lst[elem] += 1\n",
        "\n",
        "    most_common = sorted([(key, elem) for key, elem in weighted_lst.items()], key = lambda x : x[1], reverse = True)\n",
        "    return most_common\n",
        "\n",
        "def Orange_tree_to_newick(root, depth = [0]):\n",
        "\n",
        "    if root.is_leaf:\n",
        "        return str(root.value.index)  +  \":\" + f\"{root.value.height - sum(depth):.6f}\"\n",
        "\n",
        "    concat = \"(\"\n",
        "    branch_length = float(root.value.height - sum(depth))\n",
        "    for branch in root.branches:\n",
        "        concat += Orange_tree_to_newick(branch, [*depth, branch_length]) + \", \"\n",
        "\n",
        "    concat = concat[:-2] + \")\" +  \":\" + f\"{branch_length:.6f}\"\n",
        "    return concat\n",
        "\n",
        "def biotree_to_Orange_tree(tree):\n",
        "\n",
        "    def recur_parse(root, acc, depth):\n",
        "        if root.is_terminal():\n",
        "            val = root.name\n",
        "            leaf = Tree(SingletonData(range = range(len(acc), len(acc)+1), \n",
        "                                 height = depth + (root.branch_length or 0), \n",
        "                                 index = val), ())\n",
        "            acc.append(leaf)\n",
        "            return leaf\n",
        "\n",
        "        current_depth = depth + (root.branch_length or 0)\n",
        "        list_cla = []\n",
        "        for cla in root:\n",
        "            sub_tree = recur_parse(cla, acc, current_depth)\n",
        "            list_cla.append(sub_tree)\n",
        "        node = Tree(ClusterData(range = range(list_cla[0]._Tree__value.range.start, list_cla[-1]._Tree__value.range.stop),\n",
        "                            height = current_depth), tuple(list_cla))\n",
        "        return node\n",
        "\n",
        "    orange_tree = recur_parse(tree.root, [], 0)\n",
        "    return orange_tree\n",
        "\n",
        "def reroot_tree(tree):\n",
        "    newick_tree = Orange_tree_to_newick(tree)\n",
        "    biotree = Phylo.read(StringIO(newick_tree), \"newick\")\n",
        "    biotree.root_with_outgroup(biotree.root.find_clades(\"NULL\"))\n",
        "    return biotree_to_Orange_tree(biotree)\n",
        "\n",
        "def njt(table, key : str):\n",
        "\n",
        "    embeddings = {}\n",
        "    for line in table:\n",
        "        embeddings[str(line[key].value)] = list(line.attributes()) \n",
        "        \n",
        "    ids = list(map(lambda x : x.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"'\", \"_\"), embeddings.keys()))\n",
        "    data = np.array([item for item in embeddings.values()])\n",
        "    \n",
        "    cos_A = pairwise_distances(data, metric=\"cosine\")\n",
        "    \n",
        "    def constructor(x):\n",
        "        biotree = Phylo.read( StringIO(x), \"newick\")\n",
        "        return biotree_to_Orange_tree(biotree)\n",
        "\n",
        "    dm = DistanceMatrix(cos_A, ids)\n",
        "    tree = nj(dm, result_constructor = constructor)\n",
        "\n",
        "    return tree\n",
        "\n",
        "def preorder(tree, branches=attrgetter(\"branches\")):\n",
        "    stack = deque([tree])\n",
        "    while stack:\n",
        "        current = stack.popleft()\n",
        "        yield current\n",
        "        children = branches(current)\n",
        "        if children:\n",
        "            stack.extendleft(reversed(children))\n",
        "\n",
        "def clusters_at_height(root, height):\n",
        "    \"\"\"Return a list of clusters by cutting the clustering at `height`.\n",
        "    \"\"\"\n",
        "    lower = set()\n",
        "    cluster_list = []\n",
        "    for cl in preorder(root):\n",
        "        if cl in lower:\n",
        "            continue\n",
        "        if cl.value.height >= height:\n",
        "            cluster_list.append(cl)\n",
        "            lower.update(preorder(cl))\n",
        "    return cluster_list\n",
        "\n",
        "\n",
        "\n",
        "def clusterize(table : Table, threshold, key = \"embeddings\") -> Table:\n",
        "    \"\"\"clusterize a Oranga Table based on the height of THRESOLD\n",
        "    \"\"\"\n",
        "\n",
        "    root = njt(table, key)\n",
        "    # root = reroot_tree(root)\n",
        "\n",
        "    parent_cluster = parent_of_mystery(root)\n",
        "    if threshold is None:\n",
        "        threshold = parent_cluster.value.height - 0.001\n",
        "\n",
        "    cluster_tree = clusters_at_height(root, threshold)\n",
        "\n",
        "    list_cluster = {}\n",
        "    closest = None\n",
        "    mystery_len_cluster = -1\n",
        "    for i, cluster in enumerate(cluster_tree):\n",
        "        cluster_name = 'C' + str(i) \n",
        "\n",
        "        current = []\n",
        "        add_to_list(cluster, current)\n",
        "        if MYSTERY in current: \n",
        "            mystery_len_cluster = len(current)\n",
        "            closest = closest_to(parent_cluster, MYSTERY)\n",
        "\n",
        "        for item in current:\n",
        "            list_cluster[item] = cluster_name\n",
        "        # print(cluster_name, list(map(lambda x: table[x][\"embeddings\"].value, current)))\n",
        "\n",
        "    list_vocab = [line[key].value.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"'\", \"_\") for line in table]\n",
        "    table = table.add_column(StringVariable(\"Cluster\"), [list_cluster[i] if i in list_cluster.keys() else \"Out\" for i in list_vocab])\n",
        "\n",
        "    return table, closest.value.index if closest is not None else None, threshold, len(cluster_tree)\n",
        "\n",
        "from typing import List\n",
        "def one_pass(table, toguess_table, keep_cluster_line : bool = False, cluster_thresold : float = CLUSTER_THRESOLD, sim_thresold : float = SIM_THRESOLD, tips : List[str] = []):\n",
        "    assert GROUP_BY in list(map(lambda x: x.name, chain(table.domain.metas, \n",
        "                                                        table.domain.variables, \n",
        "                                                        table.domain.attributes))), \"Group by not in the Table !\"\n",
        "    supp_data = {\n",
        "        \"sim_thresold\"       : sim_thresold,\n",
        "        \"keep_cluster_line\"  : keep_cluster_line,\n",
        "    }\n",
        "\n",
        "    supp_data[\"format_at_beginning\"] = (len(table), \"x\", len(table.domain.attributes))\n",
        "    if len(table) < 3:\n",
        "        return [], supp_data\n",
        "    table, closest, thresold, nb_cluster = clusterize(table, cluster_thresold)\n",
        "    supp_data[\"cluster_thresold\"]    = thresold\n",
        "    supp_data[\"closest_to_myster\"]   = closest # table[][\"embeddings\"].value if closest is not True else None,\n",
        "    supp_data[\"number_of_cluster\"]   = nb_cluster\n",
        "    #===========================================================================\n",
        "    # Cluster split\n",
        "    toguess_cluster = [d[\"Cluster\"] for d in table if d[\"embeddings\"] == MYSTERY][0]\n",
        "\n",
        "    in_cluster_table  = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value == toguess_cluster])\n",
        "    out_cluster_table = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value != toguess_cluster])\n",
        "    #===========================================================================\n",
        "    # Group by computation\n",
        "    supp_data[\"cluster_size\"] = len(in_cluster_table)\n",
        "    if len(in_cluster_table) <= 1: return [], supp_data\n",
        "    \n",
        "    main_superclass_count_list = compute([row[GROUP_BY].value for row in in_cluster_table], tips)\n",
        "    #equality case with \"?\", take the second\n",
        "    ind = 1 if main_superclass_count_list[0][0] == \"?\" and len(main_superclass_count_list) > 1 else 0\n",
        "    main_superclass = main_superclass_count_list[ind][0]\n",
        "    supp_data[\"cluster_name\"] = main_superclass\n",
        "\n",
        "    nb_dimension = len(list(in_cluster_table.domain.attributes))\n",
        "    average_cluster = Table.from_list(in_cluster_table.domain, [\n",
        "        [sum([line[i] for line in in_cluster_table]) / nb_dimension  for i in in_cluster_table.domain.attributes] + [\"cluster_average\"]\n",
        "    ])\n",
        "\n",
        "    # main_superclass_table = Table.from_list(superclass_embeddings.domain, [i for i in superclass_embeddings if i[\"embeddings\"] == main_superclass])\n",
        "    main_superclass_table = Table.concatenate([in_cluster_table, Table.from_table(in_cluster_table.domain, average_cluster)])\n",
        "    #===========================================================================\n",
        "    # thresold computation\n",
        "    to_copy_row_instance = [d for d in main_superclass_table if d[\"embeddings\"] == MYSTERY][0]\n",
        "    to_copy = list(to_copy_row_instance.attributes())\n",
        "\n",
        "    to_compare_row_instance = [d for d in main_superclass_table if d[\"Cluster\"] == \"?\"][0]\n",
        "    to_compare = list(to_compare_row_instance.attributes())\n",
        "\n",
        "    dead_row = [k for k, (i, j) in enumerate(zip(to_copy, to_compare)) if abs(i - j) <= sim_thresold]\n",
        "    supp_data[\"removed_col\"] = len(dead_row) \n",
        "    #===========================================================================\n",
        "    # reconstruct the table filtering dead row and cluster. Remove used cluster row if \n",
        "    # keep_cluster_line is set to False\n",
        "    new_domain = Domain(attributes = [i for i in out_cluster_table.domain.attributes if int(i.name) not in dead_row], \n",
        "                        metas      = [i for i in out_cluster_table.domain.metas if i.name != \"Cluster\"])\n",
        "\n",
        "    # do the same on the data\n",
        "    data_attr, data_meta = [], []\n",
        "    whole_data = list(out_cluster_table) + list(toguess_table)\n",
        "    if keep_cluster_line: whole_data += list(in_cluster_table)\n",
        "\n",
        "    for rowinstance in whole_data:\n",
        "        data_attr.append([rowinstance[k] for k, i in enumerate(out_cluster_table.domain.attributes) if int(i.name) not in dead_row])\n",
        "        # data_attr.append([rowinstance[k] for k, i in enumerate(out_cluster_table.domain.attributes)])\n",
        "        data_meta.append([rowinstance.metas[k] for k, i in enumerate(out_cluster_table.domain.metas) if i.name != \"Cluster\"])\n",
        "\n",
        "\n",
        "    return Table.from_numpy(new_domain, X = data_attr, metas = data_meta), supp_data\n",
        "\n",
        "\n",
        "def standardize_first(table):\n",
        "    values = table[0]\n",
        "    mean = np.mean(values)\n",
        "    std  = np.std(values)\n",
        "\n",
        "    for v in range(len(values)):\n",
        "        values[v] = (values[v] - mean) / std\n",
        "\n",
        "    return Table.from_numpy(table.domain, [values], None, table.metas)"
      ],
      "metadata": {
        "id": "nPhqx45tbDSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mystery(complete_table, mystery, cluster_thresold_lambda, sim_thresold_lambda, tips):\n",
        "\n",
        "    toguess_table = Table.from_numpy(complete_table.domain, [np.array(mystery)], Y = None, metas = np.char.asarray([[MYSTERY, \"?\", \"?\"]]))\n",
        "    # toguess_table = standardize_first(toguess_table)\n",
        "\n",
        "    null_table = Table.from_numpy(complete_table.domain, [np.array([1 for i in range(len(complete_table.domain.attributes))])], Y = None, metas = np.char.asarray([[\"NULL\", \"?\", \"?\"]]))\n",
        "\n",
        "    table = Table.concatenate([complete_table, toguess_table, null_table])\n",
        "    old_table = table\n",
        "\n",
        "    advancement = []\n",
        "    for i in range(5):\n",
        "        old_table = table\n",
        "        table, data = one_pass(table, toguess_table,\n",
        "                                      keep_cluster_line = False, \n",
        "                                      cluster_thresold  = cluster_thresold_lambda(i), \n",
        "                                      sim_thresold      = sim_thresold_lambda(i),\n",
        "                                      tips = tips)\n",
        "        advancement.append(data)\n",
        "\n",
        "        if len(table) <= 1 or data[\"cluster_size\"] < 10:\n",
        "            break\n",
        "    return advancement"
      ],
      "metadata": {
        "id": "BnjjnjQuFJxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generic_table = Table(\"/content/ResNet50-average.csv\")\n",
        "supp_info_table = Table(\"/content/class_map_imagenet.csv\")\n",
        "generic_table = left_join(generic_table, supp_info_table)\n",
        "\n",
        "print(len(generic_table))\n",
        "\n",
        "# superclass_embeddings = Table(\"/content/custom-wikipedia2vec-300_superclass.csv\")"
      ],
      "metadata": {
        "id": "g_uIdCXyw6tS",
        "outputId": "d1e6489d-cf3c-4c95-cba5-9dca9c1cd49e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "996 999\n",
            "996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myster_file = EmbeddingsLoader(\"/content/mystery_CNN.csv\")"
      ],
      "metadata": {
        "id": "nnW8xIgJThWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_result(list_dict):\n",
        "    superclass_list = []\n",
        "    for dic in list_dict:\n",
        "        if type(dic) == type(dict()) and \"cluster_name\" in dic.keys():\n",
        "            superclass_list.append(f\"{dic['cluster_name']}[{round(dic['cluster_size'] / len(generic_table) * 100, 1)}%]({dic['closest_to_myster']})\")\n",
        "    \n",
        "    return superclass_list\n",
        "\n",
        "# cluster_thresold_lambda = lambda x : 0.10 + 0.1 * x\n",
        "cluster_thresold_lambda     = lambda x : None\n",
        "sim_thresold_lambda     = lambda x : 0.3\n",
        "\n",
        "tips = [[\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"monotreme\"],\n",
        "        [\"monotreme\"],\n",
        "        [\"monotreme\"],\n",
        "        [\"cat\"],\n",
        "        [\"rodent\"],\n",
        "        [\"dog\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"]]\n",
        "\n",
        "for k, (i, embeddings) in enumerate(myster_file.embeddings.items()):\n",
        "\n",
        "    result = solve_mystery(generic_table, embeddings, cluster_thresold_lambda, sim_thresold_lambda, tips[k])\n",
        "    print(f\"{' + '.join(format_result(result)): <80}\\t\\t{result}\")\n"
      ],
      "metadata": {
        "id": "AgI9x2O0Pkv4",
        "outputId": "75041d39-6975-4033-c8d0-942aee5de775",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vehicle[0.8%](jinrikisha)                                                       \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 2048), 'cluster_thresold': 0.086112, 'closest_to_myster': 'jinrikisha', 'number_of_cluster': 205, 'cluster_size': 8, 'cluster_name': 'vehicle', 'removed_col': 960}]\n",
            "dog[1.7%](schipperke) + dog[11.5%](Cardigan) + bird[15.5%](crane) + bug[15.7%](rapeseed) + ?[0.2%](NULL)\t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 2048), 'cluster_thresold': 0.122675, 'closest_to_myster': 'schipperke', 'number_of_cluster': 299, 'cluster_size': 17, 'cluster_name': 'dog', 'removed_col': 1145}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (982, 'x', 903), 'cluster_thresold': 0.048677, 'closest_to_myster': 'Cardigan', 'number_of_cluster': 88, 'cluster_size': 115, 'cluster_name': 'dog', 'removed_col': 109}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (868, 'x', 861), 'cluster_thresold': 0.039814999999999996, 'closest_to_myster': 'crane', 'number_of_cluster': 62, 'cluster_size': 154, 'cluster_name': 'bird', 'removed_col': 528}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (715, 'x', 659), 'cluster_thresold': 0.020249999999999997, 'closest_to_myster': 'rapeseed', 'number_of_cluster': 20, 'cluster_size': 156, 'cluster_name': 'bug', 'removed_col': 409}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (560, 'x', 577), 'cluster_thresold': 0.011116999999999998, 'closest_to_myster': 'NULL', 'number_of_cluster': 13, 'cluster_size': 2, 'cluster_name': '?', 'removed_col': 324}]\n",
            "vehicle[0.8%](jinrikisha)                                                       \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 2048), 'cluster_thresold': 0.10722299999999998, 'closest_to_myster': 'jinrikisha', 'number_of_cluster': 288, 'cluster_size': 8, 'cluster_name': 'vehicle', 'removed_col': 994}]\n",
            "monotreme[0.2%](platypus)                                                       \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 2048), 'cluster_thresold': 0.186509, 'closest_to_myster': 'platypus', 'number_of_cluster': 404, 'cluster_size': 2, 'cluster_name': 'monotreme', 'removed_col': 1185}]\n",
            "monotreme[0.2%](platypus)                                                       \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 2048), 'cluster_thresold': 0.21114, 'closest_to_myster': 'platypus', 'number_of_cluster': 421, 'cluster_size': 2, 'cluster_name': 'monotreme', 'removed_col': 1142}]\n",
            "monotreme[0.2%](platypus)                                                       \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 2048), 'cluster_thresold': 0.164558, 'closest_to_myster': 'platypus', 'number_of_cluster': 393, 'cluster_size': 2, 'cluster_name': 'monotreme', 'removed_col': 1152}]\n",
            "furniture[0.3%](pool_table)                                                     \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 2048), 'cluster_thresold': 0.048521, 'closest_to_myster': 'pool_table', 'number_of_cluster': 86, 'cluster_size': 3, 'cluster_name': 'furniture', 'removed_col': 936}]\n",
            "ball[0.2%](croquet_ball)                                                        \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 2048), 'cluster_thresold': 0.10391600000000001, 'closest_to_myster': 'croquet_ball', 'number_of_cluster': 276, 'cluster_size': 2, 'cluster_name': 'ball', 'removed_col': 1022}]\n",
            "dog[13.3%](cocker_spaniel) + bird[27.8%](ox) + cat[0.9%](Siamese_cat)           \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 2048), 'cluster_thresold': 0.067745, 'closest_to_myster': 'cocker_spaniel', 'number_of_cluster': 150, 'cluster_size': 132, 'cluster_name': 'dog', 'removed_col': 1104}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (867, 'x', 944), 'cluster_thresold': 0.030725000000000002, 'closest_to_myster': 'ox', 'number_of_cluster': 45, 'cluster_size': 277, 'cluster_name': 'bird', 'removed_col': 165}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (591, 'x', 858), 'cluster_thresold': 0.025056999999999996, 'closest_to_myster': 'Siamese_cat', 'number_of_cluster': 29, 'cluster_size': 9, 'cluster_name': 'cat', 'removed_col': 449}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7YVJ5THVguaG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}