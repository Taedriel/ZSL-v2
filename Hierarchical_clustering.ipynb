{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hierarchical clustering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO51Ar2Pw3SPNB3f8gn0hKS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taedriel/ZSL-v2/blob/wordEmbedding/Hierarchical_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install orange3 python-louvain networkx dendropy --quiet --upgrade"
      ],
      "metadata": {
        "id": "-nHn1AH78gzp"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import community.community_louvain as community\n",
        "import dendropy\n",
        "from Orange.clustering.hierarchical import Tree, ClusterData, SingletonData, dist_matrix_linkage, tree_from_linkage, data_clustering, leaves, WEIGHTED\n",
        "from Orange.data import Table, Domain\n",
        "from Orange.distance.distance import Cosine\n",
        "from Orange.widgets.unsupervised.owhierarchicalclustering import clusters_at_height\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from Orange.data.variable import StringVariable"
      ],
      "metadata": {
        "id": "HSkbQhDIG0Et"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsLoader:\n",
        "\n",
        "    \"\"\"class that load an embeddings file to perform operation on it. Base class\n",
        "     for multiple operations such as matrix similarity operations.\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, filename : str):\n",
        "\n",
        "        self.file = filename\n",
        "        self.embeddings = {}\n",
        "\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            with open(self.file, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "                \n",
        "            for line in lines[1:]:\n",
        "                data = line.split(\",\")\n",
        "                self.embeddings[data[0]] = torch.FloatTensor(list(map(float, data[1:])))\n",
        "\n",
        "        except IOError as e:\n",
        "            raise IOError(f\"No file {self.file}\")\n"
      ],
      "metadata": {
        "id": "F9r4YQQI9kpr"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Solver"
      ],
      "metadata": {
        "id": "6a4--t_QLVl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLUSTER_THRESOLD = 0.85\n",
        "GROUP_BY = \"first superclass\"\n",
        "MYSTERY = \"TOGUESS\"\n",
        "SIM_THRESOLD = 0.3\n",
        "\n",
        "def left_join(complete_table, supp_info_table, key: str = \"embeddings\") -> Table:\n",
        "    \"\"\"add all <b> metas </b> column from supp_info_table to complete_table using key as joint\n",
        "    \"\"\"\n",
        "    assert key in list(map(lambda x : x.name, supp_info_table.domain.metas)), \"embeddings name not present in additional data\"\n",
        "    # assert len(complete_table) == len(supp_info_table), \"table don't contain the same number of line\"\n",
        "\n",
        "    name_supp_data = [i.name for i in chain(supp_info_table.domain.metas, \n",
        "                                            supp_info_table.domain.variables, \n",
        "                                            supp_info_table.attributes) if i.name != key]\n",
        "                                            \n",
        "    supp_list_list = [[] for i in range(len(name_supp_data))]\n",
        "\n",
        "    for s in complete_table:\n",
        "        done = False\n",
        "        for d in supp_info_table:\n",
        "            if s[key] == d[key]:\n",
        "                for i, name in enumerate(name_supp_data):\n",
        "                    supp_list_list[i].append(d[name])\n",
        "                done = True\n",
        "                break\n",
        "        if not done:\n",
        "            for i, name in enumerate(name_supp_data):\n",
        "                supp_list_list[i].append(\"?\")\n",
        "\n",
        "    for i, name in enumerate(name_supp_data):\n",
        "        # print(f\"adding {name}\")\n",
        "        complete_table = complete_table.add_column(StringVariable(name), supp_list_list[i])\n",
        "\n",
        "    return complete_table\n",
        "\n",
        "def parent_of_mystery(cluster, mystery_index):\n",
        "    res = None\n",
        "    for branch in cluster.branches:\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                return cluster\n",
        "        else: \n",
        "            res = parent_of_mystery(branch, mystery_index)\n",
        "            if res is not None:\n",
        "                return res\n",
        "    \n",
        "def first_child(root):\n",
        "    if root.is_leaf:\n",
        "        return root\n",
        "    else:\n",
        "        return first_child(root.branches[0])\n",
        "\n",
        "\n",
        "def closest_to(cluster, mystery_index):\n",
        "    if len(cluster.branches) == 1:\n",
        "        return None\n",
        "\n",
        "    next = False\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        if next:\n",
        "            return first_child(branch)\n",
        "\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                if i == 0:\n",
        "                    next = True\n",
        "                else:\n",
        "                    return first_child(cluster.branches[i-1])\n",
        "\n",
        "def add_to_list(cluster, list_to_add_to):\n",
        "    \"\"\" decompose a cluster tree by adding the index of all children in the list\n",
        "    \"\"\"\n",
        "    if cluster.is_leaf:\n",
        "        list_to_add_to.append(cluster.value.index)\n",
        "\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        add_to_list(branch, list_to_add_to)\n",
        "\n",
        "def compute(lst):\n",
        "    # return max(lst,key=lst.count)\n",
        "    counter = Counter(lst)\n",
        "    return counter.most_common(len(lst))\n",
        "\n",
        "def Orange_tree_to_newick(root):\n",
        "\n",
        "    if root.is_leaf:\n",
        "        return str(root.value.index)  +  \":\" + str(root.value.height)\n",
        "\n",
        "    concat = \"(\"\n",
        "    for branch in root.branches:\n",
        "\n",
        "        concat += Orange_tree_to_newick(branch) + \",\"\n",
        "\n",
        "    concat = concat[:-1] + \")\" +  \":\" + str(root.value.height)\n",
        "    return concat\n",
        "\n",
        "def newick_to_Orange_tree(newick, acc, d):\n",
        "\n",
        "    if newick.is_leaf():\n",
        "        return Tree(SingletonData(range=(acc, acc + 1), height=0.0, index=newick.taxon),()), acc + 1, 0\n",
        "\n",
        "    list_orange_subtree = []\n",
        "    for node in newick.child_node_iter():\n",
        "        node, acc, d = newick_to_Orange_tree(node, acc, d)\n",
        "        list_orange_subtree.append(node)\n",
        "\n",
        "    return Tree(ClusterData(range=(acc, acc + len(list_orange_subtree)), height=d + newick.edge_length),\n",
        "                 tuple(list_orange_subtree)), acc + len(list_orange_subtree), newick.edge_length\n",
        "\n",
        "    \n",
        "def reroot_tree(tree, void_index):\n",
        "\n",
        "    newick_tree = '(' + Orange_tree_to_newick(tree) + ');'\n",
        "    dendro_tree = dendropy.Tree.get_from_string(newick_tree, \"newick\")\n",
        "    \n",
        "    outgroup_node = dendro_tree.find_node_with_taxon_label(str(void_index))\n",
        "    dendro_tree.to_outgroup_position(outgroup_node, update_bipartitions=False)\n",
        "\n",
        "    print(dendro_tree.phylogenetic_distance_matrix())\n",
        "    \n",
        "\n",
        "    #r, acc, d = newick_to_Orange_tree(list(iter(dendro_tree))[0], 0, 0)\n",
        "    # print(r)\n",
        "    # print(acc, d)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def clusterize(table : Table, thresold, key = \"embeddings\") -> Table:\n",
        "    \"\"\"clusterize a Oranga Table based on the height of THRESOLD\n",
        "    \"\"\"\n",
        "\n",
        "    # null = Table.from_numpy(table.domain, [np.array([1 for i in range(len(table.domain.attributes))])], Y = None, metas = np.char.asarray([[\"NULL\", \"?\", \"?\"]]))\n",
        "    # table = Table.concatenate([table, null])\n",
        "\n",
        "    for i in table[-1::-1]:\n",
        "        if i[key] == MYSTERY:\n",
        "            mystery_index = table.index(i)\n",
        "            break\n",
        "    # for i in table[-1::-1]:\n",
        "    #     if i[key] == \"NULL\":\n",
        "    #         void_index = table.index(i)\n",
        "    #         break\n",
        "\n",
        "    root = data_clustering(table, distance=Cosine, linkage=WEIGHTED)\n",
        "    # root = reroot_tree(root, void_index)\n",
        "    parent_cluster = parent_of_mystery(root, mystery_index)\n",
        "    if thresold is None:\n",
        "        thresold = min(parent_cluster.value.height + 0.05, 1)\n",
        "\n",
        "    cluster_tree = clusters_at_height(root, thresold)\n",
        "\n",
        "    list_cluster = {}\n",
        "    closest = None\n",
        "    mystery_len_cluster = -1\n",
        "    for i, cluster in enumerate(cluster_tree):\n",
        "        cluster_name     = 'C' + str(i) \n",
        "\n",
        "        current = []\n",
        "        add_to_list(cluster, current)\n",
        "        if mystery_index in current: \n",
        "            mystery_len_cluster = len(current)\n",
        "            closest = closest_to(parent_cluster, mystery_index)\n",
        "\n",
        "        for item_index in current:\n",
        "            list_cluster[item_index] = cluster_name\n",
        "        # print(cluster_name, list(map(lambda x: table[x][\"embeddings\"].value, current)))\n",
        "\n",
        "    # print(f\"last cluster: {i} ({mystery_len_cluster})\")\n",
        "    table = table.add_column(StringVariable(\"Cluster\"), [list_cluster[i] for i in range(len(table))])\n",
        "\n",
        "    return table, closest.value.index, thresold, i\n",
        "\n",
        "def one_pass(table, toguess_table, keep_cluster_line : bool = False, cluster_thresold : float = CLUSTER_THRESOLD, sim_thresold : float = SIM_THRESOLD):\n",
        "    assert GROUP_BY in list(map(lambda x: x.name, chain(table.domain.metas, \n",
        "                                                        table.domain.variables, \n",
        "                                                        table.domain.attributes))), \"Group by not in the Table !\"\n",
        "    supp_data = {\n",
        "        \"sim_thresold\"       : sim_thresold,\n",
        "        \"keep_cluster_line\"  : keep_cluster_line,\n",
        "    }\n",
        "\n",
        "    supp_data[\"format_at_beginning\"] = (len(table), \"x\", len(table.domain.attributes))\n",
        "    table, closest, thresold, nb_cluster = clusterize(table, cluster_thresold)\n",
        "    supp_data[\"cluster_thresold\"]    = thresold\n",
        "    supp_data[\"closest_to_myster\"]   = table[closest][\"embeddings\"].value if closest is not True else None,\n",
        "    supp_data[\"number_of_cluster\"]   = nb_cluster\n",
        "    #===========================================================================\n",
        "    # Cluster split\n",
        "    toguess_cluster = [d[\"Cluster\"] for d in table if d[\"embeddings\"] == MYSTERY][0]\n",
        "\n",
        "    in_cluster_table  = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value == toguess_cluster])\n",
        "    out_cluster_table = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value != toguess_cluster])\n",
        "    #===========================================================================\n",
        "    # Group by computation\n",
        "    supp_data[\"cluster_size\"] = len(in_cluster_table)\n",
        "    if len(in_cluster_table) <= 1: return [], supp_data\n",
        "    \n",
        "    main_superclass_count_list = compute([row[GROUP_BY].value for row in in_cluster_table])\n",
        "    #equality case with \"?\", take the second\n",
        "    ind = 1 if main_superclass_count_list[0][0] == \"?\" and len(main_superclass_count_list) > 1 else 0\n",
        "    main_superclass = main_superclass_count_list[ind][0]\n",
        "    supp_data[\"cluster_name\"] = main_superclass\n",
        "\n",
        "    nb_dimension = len(list(in_cluster_table.domain.attributes))\n",
        "    average_cluster = Table.from_list(in_cluster_table.domain, [\n",
        "        [sum([line[i] for line in in_cluster_table]) / nb_dimension  for i in in_cluster_table.domain.attributes] + [\"cluster_average\"]\n",
        "    ])\n",
        "\n",
        "    # main_superclass_table = Table.from_list(superclass_embeddings.domain, [i for i in superclass_embeddings if i[\"embeddings\"] == main_superclass])\n",
        "    main_superclass_table = Table.concatenate([in_cluster_table, Table.from_table(in_cluster_table.domain, average_cluster)])\n",
        "    #===========================================================================\n",
        "    # thresold computation\n",
        "    to_copy_row_instance = [d for d in main_superclass_table if d[\"embeddings\"] == MYSTERY][0]\n",
        "    to_copy = list(to_copy_row_instance.attributes())\n",
        "\n",
        "    to_compare_row_instance = [d for d in main_superclass_table if d[\"Cluster\"] == \"?\"][0]\n",
        "    to_compare = list(to_compare_row_instance.attributes())\n",
        "\n",
        "    dead_row = [k for k, (i, j) in enumerate(zip(to_copy, to_compare)) if abs(i - j) <= sim_thresold]\n",
        "    supp_data[\"removed_col\"] = len(dead_row) \n",
        "    #===========================================================================\n",
        "    # reconstruct the table filtering dead row and cluster. Remove used cluster row if \n",
        "    # keep_cluster_line is set to False\n",
        "    new_domain = Domain(attributes = [i for i in out_cluster_table.domain.attributes if int(i.name) not in dead_row], \n",
        "                        metas      = [i for i in out_cluster_table.domain.metas if i.name != \"Cluster\"])\n",
        "\n",
        "    # do the same on the data\n",
        "    data_attr, data_meta = [], []\n",
        "    whole_data = list(out_cluster_table) + list(toguess_table)\n",
        "    if keep_cluster_line: whole_data += list(in_cluster_table)\n",
        "\n",
        "    for rowinstance in whole_data:\n",
        "        data_attr.append([rowinstance[k] for k, i in enumerate(out_cluster_table.domain.attributes) if int(i.name) not in dead_row])\n",
        "        data_meta.append([rowinstance.metas[k] for k, i in enumerate(out_cluster_table.domain.metas) if i.name != \"Cluster\"])\n",
        "\n",
        "    return Table.from_numpy(new_domain, X = data_attr, metas = data_meta), supp_data\n",
        "\n",
        "\n",
        "def standardize_first(table):\n",
        "    values = table[0]\n",
        "    mean = np.mean(values)\n",
        "    std  = np.std(values)\n",
        "\n",
        "    for v in range(len(values)):\n",
        "        values[v] = (values[v] - mean) / std\n",
        "\n",
        "    return Table.from_numpy(table.domain, [values], None, table.metas)"
      ],
      "metadata": {
        "id": "nPhqx45tbDSE"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mystery(complete_table, mystery, cluster_thresold_lambda, sim_thresold_lambda):\n",
        "\n",
        "    toguess_table = Table.from_numpy(complete_table.domain, [np.array(mystery)], Y = None, metas = np.char.asarray([[MYSTERY, \"?\", \"?\"]]))\n",
        "    # toguess_table = standardize_first(toguess_table)\n",
        "\n",
        "    table = Table.concatenate([complete_table, toguess_table])\n",
        "    old_table = table\n",
        "\n",
        "    advancement = []\n",
        "    for i in range(5):\n",
        "        old_table = table\n",
        "        table, data = one_pass(table, toguess_table,\n",
        "                                      keep_cluster_line = False, \n",
        "                                      cluster_thresold  = cluster_thresold_lambda(i), \n",
        "                                      sim_thresold      = sim_thresold_lambda(i))\n",
        "        advancement.append(data)\n",
        "\n",
        "        if len(table) <= 1 or data[\"cluster_size\"] < 10:\n",
        "            break\n",
        "    return advancement\n",
        "\n",
        "            # print(\"no result, trying to upper cluster thresold\")\n",
        "            # current_cluster_thresold = 0.55 + 0.05\n",
        "            # while current_cluster_thresold < 1 and len(current_table) == 0:\n",
        "            #     current_table, data = one_pass(old_table, keep_cluster_line = False, cluster_thresold = current_cluster_thresold, sim_thresold = 0.3 + 0.05 * i)\n",
        "            #     print(data)\n",
        "            #     current_cluster_thresold += 0.05\n",
        "            # if len(current_table) == 0:\n",
        "            #     print(\"no suitable thresold...\")\n",
        "            #     break\n",
        "            # print(\"find a suitable thresold, resuming\")"
      ],
      "metadata": {
        "id": "BnjjnjQuFJxe"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generic_table = Table(\"/content/Ayoub-average_without_dog.csv\")\n",
        "supp_info_table = Table(\"/content/class_map_imagenet.csv\")\n",
        "generic_table = left_join(generic_table, supp_info_table)\n",
        "\n",
        "# superclass_embeddings = Table(\"/content/custom-wikipedia2vec-300_superclass.csv\")"
      ],
      "metadata": {
        "id": "g_uIdCXyw6tS"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myster_file = EmbeddingsLoader(\"/content/mystery.csv\")"
      ],
      "metadata": {
        "id": "nnW8xIgJThWR"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_result(list_dict):\n",
        "    superclass_list = []\n",
        "    for dic in list_dict:\n",
        "        if type(dic) == type(dict()) and \"cluster_name\" in dic.keys():\n",
        "            superclass_list.append(f\"{dic['cluster_name']}({dic['closest_to_myster']})\")\n",
        "    \n",
        "    return superclass_list\n",
        "\n",
        "# cluster_thresold_lambda = lambda x : 0.30 + 0.20 * x\n",
        "cluster_thresold_lambda     = lambda x : None\n",
        "sim_thresold_lambda     = lambda x : 0.3\n",
        "\n",
        "for i, embeddings in myster_file.embeddings.items():\n",
        "\n",
        "    result = solve_mystery(generic_table, embeddings, cluster_thresold_lambda, sim_thresold_lambda)\n",
        "    print(f\"{i}\\t{' + '.join(format_result(result)): <80}\\t\\t{result}\")\n"
      ],
      "metadata": {
        "id": "AgI9x2O0Pkv4",
        "outputId": "4a622769-e82d-49e8-ba23-9471a49fcf59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\tcat(('muzzle',)) + vehicle(('dogsled',))                                        \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (878, 'x', 300), 'cluster_thresold': 0.25875283666076765, 'closest_to_myster': ('muzzle',), 'number_of_cluster': 39, 'cluster_size': 12, 'cluster_name': 'cat', 'removed_col': 28}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (867, 'x', 272), 'cluster_thresold': 0.2892776601366566, 'closest_to_myster': ('dogsled',), 'number_of_cluster': 29, 'cluster_size': 5, 'cluster_name': 'vehicle', 'removed_col': 0}]\n",
            "1\tcat(('muzzle',)) + ball(('pool table',))                                        \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (878, 'x', 300), 'cluster_thresold': 0.26559823692125467, 'closest_to_myster': ('muzzle',), 'number_of_cluster': 37, 'cluster_size': 12, 'cluster_name': 'cat', 'removed_col': 36}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (867, 'x', 264), 'cluster_thresold': 0.3183370245557002, 'closest_to_myster': ('pool table',), 'number_of_cluster': 25, 'cluster_size': 16, 'cluster_name': 'ball', 'removed_col': 2}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (852, 'x', 263), 'cluster_thresold': 1, 'closest_to_myster': ('rapeseed',), 'number_of_cluster': 1, 'cluster_size': 1}]\n",
            "2\tcat(('muzzle',)) + bird(('menu',)) + butterfly(('web site',))                   \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (878, 'x', 300), 'cluster_thresold': 0.2852544796313553, 'closest_to_myster': ('muzzle',), 'number_of_cluster': 31, 'cluster_size': 12, 'cluster_name': 'cat', 'removed_col': 29}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (867, 'x', 271), 'cluster_thresold': 0.4919533987871173, 'closest_to_myster': ('menu',), 'number_of_cluster': 4, 'cluster_size': 862, 'cluster_name': 'bird', 'removed_col': 16}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (6, 'x', 259), 'cluster_thresold': 0.9707561773029802, 'closest_to_myster': ('web site',), 'number_of_cluster': 0, 'cluster_size': 6, 'cluster_name': 'butterfly', 'removed_col': 22}]\n",
            "4\tfish(('platypus',))                                                             \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (878, 'x', 300), 'cluster_thresold': 0.10475503830562323, 'closest_to_myster': ('platypus',), 'number_of_cluster': 203, 'cluster_size': 7, 'cluster_name': 'fish', 'removed_col': 32}]\n",
            "5\tbird(('tree frog',)) + dinosaur(('triceratops',))                               \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (878, 'x', 300), 'cluster_thresold': 0.2875845825332311, 'closest_to_myster': ('tree frog',), 'number_of_cluster': 30, 'cluster_size': 141, 'cluster_name': 'bird', 'removed_col': 38}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (738, 'x', 262), 'cluster_thresold': 0.2384788272705583, 'closest_to_myster': ('triceratops',), 'number_of_cluster': 44, 'cluster_size': 2, 'cluster_name': 'dinosaur', 'removed_col': 26}]\n",
            "6\tmonotreme(('platypus',))                                                        \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (878, 'x', 300), 'cluster_thresold': 0.11783875967264064, 'closest_to_myster': ('platypus',), 'number_of_cluster': 166, 'cluster_size': 5, 'cluster_name': 'monotreme', 'removed_col': 43}]\n",
            "7\tcat(('triceratops',)) + snake(('barracouta',)) + bird(('web site',))            \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (878, 'x', 300), 'cluster_thresold': 0.24368710047986192, 'closest_to_myster': ('triceratops',), 'number_of_cluster': 44, 'cluster_size': 13, 'cluster_name': 'cat', 'removed_col': 28}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (866, 'x', 272), 'cluster_thresold': 0.24432020094003032, 'closest_to_myster': ('barracouta',), 'number_of_cluster': 41, 'cluster_size': 87, 'cluster_name': 'snake', 'removed_col': 12}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (780, 'x', 260), 'cluster_thresold': 1, 'closest_to_myster': ('web site',), 'number_of_cluster': 0, 'cluster_size': 780, 'cluster_name': 'bird', 'removed_col': 7}]\n",
            "8\tcat(('muzzle',)) + bird(('triceratops',))                                       \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (878, 'x', 300), 'cluster_thresold': 0.252793191752333, 'closest_to_myster': ('muzzle',), 'number_of_cluster': 39, 'cluster_size': 12, 'cluster_name': 'cat', 'removed_col': 36}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (867, 'x', 264), 'cluster_thresold': 0.23385392626504226, 'closest_to_myster': ('triceratops',), 'number_of_cluster': 43, 'cluster_size': 43, 'cluster_name': 'bird', 'removed_col': 5}, {'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (825, 'x', 259), 'cluster_thresold': 1, 'closest_to_myster': ('web site',), 'number_of_cluster': 1, 'cluster_size': 1}]\n",
            "9\tother(('muzzle',))                                                              \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (878, 'x', 300), 'cluster_thresold': 0.1442504404070874, 'closest_to_myster': ('muzzle',), 'number_of_cluster': 124, 'cluster_size': 2, 'cluster_name': 'other', 'removed_col': 34}]\n"
          ]
        }
      ]
    }
  ]
}