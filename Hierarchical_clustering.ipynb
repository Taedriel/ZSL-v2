{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hierarchical clustering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJtiRikUHV39Z+lIZGBva9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taedriel/ZSL-v2/blob/wordEmbedding/Hierarchical_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install orange3 python-louvain networkx --quiet --upgrade"
      ],
      "metadata": {
        "id": "-nHn1AH78gzp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import community.community_louvain as community\n",
        "from Orange.clustering.hierarchical import dist_matrix_linkage, tree_from_linkage, data_clustering, leaves, WEIGHTED\n",
        "from Orange.data import Table, Domain\n",
        "from Orange.distance.distance import Cosine\n",
        "from Orange.widgets.unsupervised.owhierarchicalclustering import clusters_at_height\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from Orange.data.variable import StringVariable"
      ],
      "metadata": {
        "id": "HSkbQhDIG0Et"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsLoader:\n",
        "\n",
        "    \"\"\"class that load an embeddings file to perform operation on it. Base class\n",
        "     for multiple operations such as matrix similarity operations.\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, filename : str):\n",
        "\n",
        "        self.file = filename\n",
        "        self.embeddings = {}\n",
        "\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            with open(self.file, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "                \n",
        "            for line in lines[1:]:\n",
        "                data = line.split(\",\")\n",
        "                self.embeddings[data[0]] = torch.FloatTensor(list(map(float, data[1:])))\n",
        "\n",
        "        except IOError as e:\n",
        "            raise IOError(f\"No file {self.file}\")\n"
      ],
      "metadata": {
        "id": "F9r4YQQI9kpr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Solver"
      ],
      "metadata": {
        "id": "6a4--t_QLVl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLUSTER_THRESOLD = 0.85\n",
        "GROUP_BY = \"first superclass\"\n",
        "MYSTERY = \"TOGUESS\"\n",
        "SIM_THRESOLD = 0.3\n",
        "\n",
        "def left_join(complete_table, supp_info_table, key: str = \"embeddings\") -> Table:\n",
        "    \"\"\"add all <b> metas </b> column from supp_info_table to complete_table using key as joint\n",
        "    \"\"\"\n",
        "    assert key in list(map(lambda x : x.name, supp_info_table.domain.metas)), \"embeddings name not present in additional data\"\n",
        "    # assert len(complete_table) == len(supp_info_table), \"table don't contain the same number of line\"\n",
        "\n",
        "    name_supp_data = [i.name for i in chain(supp_info_table.domain.metas, \n",
        "                                            supp_info_table.domain.variables, \n",
        "                                            supp_info_table.attributes) if i.name != key]\n",
        "                                            \n",
        "    supp_list_list = [[] for i in range(len(name_supp_data))]\n",
        "\n",
        "    for s in complete_table:\n",
        "        done = False\n",
        "        for d in supp_info_table:\n",
        "            if s[key] == d[key]:\n",
        "                for i, name in enumerate(name_supp_data):\n",
        "                    supp_list_list[i].append(d[name])\n",
        "                done = True\n",
        "                break\n",
        "        if not done:\n",
        "            for i, name in enumerate(name_supp_data):\n",
        "                supp_list_list[i].append(\"?\")\n",
        "\n",
        "    for i, name in enumerate(name_supp_data):\n",
        "        # print(f\"adding {name}\")\n",
        "        complete_table = complete_table.add_column(StringVariable(name), supp_list_list[i])\n",
        "\n",
        "    return complete_table\n",
        "\n",
        "def parent_of_mystery(cluster, mystery_index):\n",
        "    res = None\n",
        "    for branch in cluster.branches:\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                return cluster\n",
        "        else: \n",
        "            res = parent_of_mystery(branch, mystery_index)\n",
        "            if res is not None:\n",
        "                return res\n",
        "    \n",
        "def first_child(root):\n",
        "    if root.is_leaf:\n",
        "        return root\n",
        "    else:\n",
        "        return first_child(root.branches[0])\n",
        "\n",
        "\n",
        "def closest_to(cluster, mystery_index):\n",
        "    if len(cluster.branches) == 1:\n",
        "        return None\n",
        "\n",
        "    next = False\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        if next:\n",
        "            return first_child(branch)\n",
        "\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                if i == 0:\n",
        "                    next = True\n",
        "                else:\n",
        "                    return first_child(cluster.branches[i-1])\n",
        "\n",
        "def add_to_list(cluster, list_to_add_to):\n",
        "    \"\"\" decompose a cluster tree by adding the index of all children in the list\n",
        "    \"\"\"\n",
        "    if cluster.is_leaf:\n",
        "        list_to_add_to.append(cluster.value.index)\n",
        "\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        add_to_list(branch, list_to_add_to)\n",
        "\n",
        "def clusterize(table : Table, thresold, key = \"embeddings\") -> Table:\n",
        "    \"\"\"clusterize a Oranga Table based on the height of THRESOLD\n",
        "    \"\"\"\n",
        "    for i in table[-1::-1]:\n",
        "        if i[key] == MYSTERY:\n",
        "            mystery_index = table.index(i)\n",
        "            break\n",
        "\n",
        "    root = data_clustering(table, distance=Cosine, linkage=WEIGHTED)\n",
        "    parent_cluster = parent_of_mystery(root, mystery_index)\n",
        "    print(parent_cluster.value.height)\n",
        "\n",
        "    cluster_tree = clusters_at_height(root, thresold)\n",
        "\n",
        "    list_cluster = {}\n",
        "    closest = None\n",
        "    mystery_len_cluster = -1\n",
        "    for i, cluster in enumerate(cluster_tree):\n",
        "        cluster_name     = 'C' + str(i) \n",
        "\n",
        "        current = []\n",
        "        add_to_list(cluster, current)\n",
        "        if mystery_index in current: \n",
        "            mystery_len_cluster = len(current)\n",
        "            closest = closest_to(parent_cluster, mystery_index)\n",
        "\n",
        "        for item_index in current:\n",
        "            list_cluster[item_index] = cluster_name\n",
        "        # print(cluster_name, list(map(lambda x: table[x][\"embeddings\"].value, current)))\n",
        "\n",
        "    print(f\"last cluster: {i} ({mystery_len_cluster})\")\n",
        "    table = table.add_column(StringVariable(\"Cluster\"), [list_cluster[i] for i in range(len(table))])\n",
        "\n",
        "    return table, closest\n",
        "\n",
        "def compute(lst):\n",
        "    # return max(lst,key=lst.count)\n",
        "    counter = Counter(lst)\n",
        "    return counter.most_common(len(lst))\n",
        "\n",
        "def one_pass(table, toguess_table, keep_cluster_line : bool = False, cluster_thresold : float = CLUSTER_THRESOLD, sim_thresold : float = SIM_THRESOLD):\n",
        "    assert GROUP_BY in list(map(lambda x: x.name, chain(table.domain.metas, \n",
        "                                                        table.domain.variables, \n",
        "                                                        table.domain.attributes))), \"Group by not in the Table !\"\n",
        "    \n",
        "    format = (len(table), \"x\", len(table.domain.attributes))\n",
        "    table, closest = clusterize(table, cluster_thresold)\n",
        "    #===========================================================================\n",
        "    # Cluster split\n",
        "    toguess_cluster = [d[\"Cluster\"] for d in table if d[\"embeddings\"] == MYSTERY][0]\n",
        "\n",
        "    in_cluster_table  = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value == toguess_cluster])\n",
        "    out_cluster_table = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value != toguess_cluster])\n",
        "    \n",
        "    #===========================================================================\n",
        "    # Group by computation\n",
        "    main_superclass_count_list = compute([row[GROUP_BY].value for row in in_cluster_table])\n",
        "    #equality case with \"?\", take the second\n",
        "    ind = 1 if main_superclass_count_list[0][0] == \"?\" and len(main_superclass_count_list) > 1 else 0\n",
        "\n",
        "    main_superclass = main_superclass_count_list[ind][0]\n",
        "    main_superclass_table = Table.from_list(superclass_embeddings.domain, \n",
        "                                            [i for i in superclass_embeddings if i[\"embeddings\"] == main_superclass])\n",
        "    if len(main_superclass_table) == 0: return [], \"cluster is empty\"\n",
        "\n",
        "    main_superclass_table = Table.concatenate([in_cluster_table, Table.from_table(out_cluster_table.domain, \n",
        "                                                                                  main_superclass_table)])\n",
        "    #===========================================================================\n",
        "    # thresold computation\n",
        "    to_copy_row_instance = [d for d in main_superclass_table if d[\"embeddings\"] == MYSTERY][0]\n",
        "    to_copy = list(to_copy_row_instance.attributes())\n",
        "\n",
        "    to_compare_row_instance = [d for d in main_superclass_table if d[\"Cluster\"] == \"?\"][0]\n",
        "    to_compare = list(to_compare_row_instance.attributes())\n",
        "\n",
        "    dead_row = [k for k, (i, j) in enumerate(zip(to_copy, to_compare)) if abs(i - j) <= sim_thresold]\n",
        "    #===========================================================================\n",
        "    # reconstruct the table filtering dead row and cluster. Remove used cluster row if \n",
        "    # keep_cluster_line is set to False\n",
        "    new_domain = Domain(attributes = [i for i in out_cluster_table.domain.attributes if int(i.name) not in dead_row], \n",
        "                        metas      = [i for i in out_cluster_table.domain.metas if i.name != \"Cluster\"])\n",
        "\n",
        "    # do the same on the data\n",
        "    data_attr, data_meta = [], []\n",
        "    whole_data = list(out_cluster_table) + list(toguess_table)\n",
        "    if keep_cluster_line: whole_data += list(in_cluster_table)\n",
        "\n",
        "    for rowinstance in whole_data:\n",
        "        data_attr.append([rowinstance[k] for k, i in enumerate(out_cluster_table.domain.attributes) if int(i.name) not in dead_row])\n",
        "        data_meta.append([rowinstance.metas[k] for k, i in enumerate(out_cluster_table.domain.metas) if i.name != \"Cluster\"])\n",
        "\n",
        "    return Table.from_numpy(new_domain, X = data_attr, metas = data_meta), \\\n",
        "        { \"cluster\" : {\n",
        "                \"name\" : main_superclass,\n",
        "                \"size\" : len(in_cluster_table) - 1,\n",
        "                \"thresold\": cluster_thresold,\n",
        "                \"closest_to_myster\" : table[closest][\"embeddings\"].value if closest is not True else None\n",
        "            },\n",
        "           \"format_at_beginning\": format,\n",
        "           \"keep_cluster_line\"  : keep_cluster_line,\n",
        "           \"sim_thresold\"       : sim_thresold,\n",
        "           \"removed_col\"        : len(dead_row) \n",
        "        }\n",
        "\n",
        "def standardize_first(table):\n",
        "    values = table[0]\n",
        "    mean = np.mean(values)\n",
        "    std  = np.std(values)\n",
        "\n",
        "    for v in range(len(values)):\n",
        "        values[v] = (values[v] - mean) / std\n",
        "\n",
        "    return Table.from_numpy(table.domain, [values], None, table.metas)"
      ],
      "metadata": {
        "id": "nPhqx45tbDSE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generic_table = Table(\"/content/imagenet-wikipedia2vec-300.csv\")\n",
        "supp_info_table = Table(\"/content/class_map_imagenet.csv\")\n",
        "generic_table = left_join(generic_table, supp_info_table)\n",
        "\n",
        "superclass_embeddings = Table(\"/content/custom-wikipedia2vec-300_superclass.csv\")"
      ],
      "metadata": {
        "id": "g_uIdCXyw6tS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mystery(complete_table, mystery, cluster_thresold_lambda = lambda x : 0.55 + 0.1 * x, sim_thresold_lambda = lambda x : 0.3 + 0.05 * x):\n",
        "\n",
        "    toguess_table = Table.from_numpy(complete_table.domain, [np.array(mystery)], Y = None, metas = np.char.asarray([[MYSTERY, \"?\", \"?\"]]))\n",
        "    toguess_table = standardize_first(toguess_table)\n",
        "\n",
        "    table = Table.concatenate([complete_table, toguess_table])\n",
        "    old_table = table\n",
        "\n",
        "    advancement = []\n",
        "    for i in range(5):\n",
        "        old_table = table\n",
        "        table, data = one_pass(table, toguess_table,\n",
        "                                      keep_cluster_line = False, \n",
        "                                      cluster_thresold  = cluster_thresold_lambda(i), \n",
        "                                      sim_thresold      = sim_thresold_lambda(i))\n",
        "        advancement.append(data)\n",
        "\n",
        "        if len(table) == 0:\n",
        "            break\n",
        "    return advancement\n",
        "\n",
        "            # print(\"no result, trying to upper cluster thresold\")\n",
        "            # current_cluster_thresold = 0.55 + 0.05\n",
        "            # while current_cluster_thresold < 1 and len(current_table) == 0:\n",
        "            #     current_table, data = one_pass(old_table, keep_cluster_line = False, cluster_thresold = current_cluster_thresold, sim_thresold = 0.3 + 0.05 * i)\n",
        "            #     print(data)\n",
        "            #     current_cluster_thresold += 0.05\n",
        "            # if len(current_table) == 0:\n",
        "            #     print(\"no suitable thresold...\")\n",
        "            #     break\n",
        "            # print(\"find a suitable thresold, resuming\")"
      ],
      "metadata": {
        "id": "BnjjnjQuFJxe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myster_file = EmbeddingsLoader(\"/content/mystery.csv\")"
      ],
      "metadata": {
        "id": "nnW8xIgJThWR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_result(list_dict):\n",
        "    superclass_list = []\n",
        "    for dic in list_dict:\n",
        "        if type(dic) == type(dict()):\n",
        "            superclass_list.append((dic[\"cluster\"][\"name\"], dic[\"cluster\"][\"closest_to_myster\"]))\n",
        "    \n",
        "    return superclass_list\n",
        "\n",
        "cluster_thresold_lambda = lambda x : 0.65 + 0.05 * x\n",
        "sim_thresold_lambda     = lambda x : 0.3 + 0.05 * x\n",
        "\n",
        "for i, embeddings in myster_file.embeddings.items():\n",
        "\n",
        "    result = solve_mystery(generic_table, embeddings, cluster_thresold_lambda, sim_thresold_lambda)\n",
        "    print(i, *format_result(result), sep = \",\")\n"
      ],
      "metadata": {
        "id": "AgI9x2O0Pkv4",
        "outputId": "90a8b991-f9d6-4366-fd72-7dda5fd51c81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3471095649353513\n",
            "last cluster: 228 (100)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-9ce693ebcb16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyster_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_mystery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_thresold_lambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_thresold_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mformat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-c84cee2fdc0c>\u001b[0m in \u001b[0;36msolve_mystery\u001b[0;34m(complete_table, mystery, cluster_thresold_lambda, sim_thresold_lambda)\u001b[0m\n\u001b[1;32m     13\u001b[0m                                       \u001b[0mkeep_cluster_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                       \u001b[0mcluster_thresold\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcluster_thresold_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                       sim_thresold      = sim_thresold_lambda(i))\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0madvancement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-d015d1bb9046>\u001b[0m in \u001b[0;36mone_pass\u001b[0;34m(table, toguess_table, keep_cluster_line, cluster_thresold, sim_thresold)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;34m\"size\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_cluster_table\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;34m\"thresold\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcluster_thresold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0;34m\"closest_to_myster\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclosest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclosest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             },\n\u001b[1;32m    176\u001b[0m            \u001b[0;34m\"format_at_beginning\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/Orange/data/table.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1142\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mRowInstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_table_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/Orange/data/table.py\u001b[0m in \u001b[0;36mfrom_table_rows\u001b[0;34m(cls, source, row_indices)\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlocked_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    }
  ]
}