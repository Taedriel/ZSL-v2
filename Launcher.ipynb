{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Launcher.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+Er4D+ngkZRmKgLgsCoaT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taedriel/ZSL-v2/blob/startArchiWordEmbedding/Launcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DB9CVVe2Vta"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Taedriel/ZSL-v2.git\n",
        "!cd ZSL-v2/ ; git checkout startArchiWordEmbedding; git pull\n",
        "!cd ZSL-v2/ ; pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/ZSL-v2\")"
      ],
      "metadata": {
        "id": "b-Np1knU7I-8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from torch import Tensor\n",
        "from Orange.data import Table\n",
        "\n",
        "import zsl\n",
        "\n",
        "\n",
        "runtime = {}\n",
        "\n",
        "def check_file_presence():\n",
        "    from os.path import exists\n",
        "\n",
        "    file_to_check = [\n",
        "        \"/content/Aroub-average.csv\",\n",
        "        \"/content/class_map_imagenet.csv\",\n",
        "        \"/content/custom-wikipedia2vec-300_superclass.csv\"\n",
        "    ]\n",
        "\n",
        "    for file in file_to_check:\n",
        "        if not exists(file):\n",
        "            raise FileNotFoundError(file)\n",
        "\n",
        "def image_to_text_embedding(image_path : str) -> List[float] or Tensor:\n",
        "    return list(range(300))\n",
        "\n",
        "def text_embedding_to_classes(embedding : List[float or Tensor]) -> List[str]:\n",
        "\n",
        "    embedding = zsl.HiCA(embedding, runtime[\"prior_knowledge_table\"], runtime[\"superclass_embeddings\"]) \\\n",
        "        .solve(lambda x : 0.25 + 0.05 * x, lambda x : 0.1 + 0.05 * x)\n",
        "\n",
        "    return embedding\n",
        "\n",
        "def classes_to_prediction(image_path : str, plausible_classes : List[str]) -> List[str]:\n",
        "    return list((\"platypus\", 0.89), (\"beaver\", 0.23))\n",
        "\n",
        "def run_pipeline(image_path : str, intermediate_result = False):\n",
        "\n",
        "    text_embedding = image_to_text_embedding(image_path)\n",
        "\n",
        "    plausible_classes = text_embedding_to_classes(text_embedding)\n",
        "\n",
        "    return classes_to_prediction(image_path, plausible_classes)\n",
        "\n",
        "def preprocess():\n",
        "\n",
        "    generic_table = Table(\"/content/Aroub-average.csv\")\n",
        "    supp_info_table = Table(\"/content/class_map_imagenet.csv\")\n",
        "\n",
        "    runtime[\"prior_knowledge_table\"] = zsl.HiCA.left_join(generic_table, supp_info_table)\n",
        "    runtime[\"superclass_embeddings\"] = Table(\"/content/custom-wikipedia2vec-300_superclass.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    check_file_presence()\n",
        "    preprocess()\n",
        "    result, _ = run_pipeline(\"examples/002.png\", intermediate_result = False)\n",
        "\n"
      ],
      "metadata": {
        "id": "vdcKTAwQ34kT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}