{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hierarchical clustering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYuscX13oEEVi1MZM2WDYl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taedriel/ZSL-v2/blob/wordEmbedding/Hierarchical_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install orange3 python-louvain networkx dendropy biopython scikit-bio --quiet --upgrade"
      ],
      "metadata": {
        "id": "-nHn1AH78gzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import community.community_louvain as community\n",
        "import dendropy\n",
        "# if import error, launch import a second time, and it will be fine\n",
        "from Orange.clustering.hierarchical import Tree, ClusterData, SingletonData, dist_matrix_linkage, tree_from_linkage, data_clustering, leaves, WEIGHTED, dist_matrix_clustering\n",
        "from Orange.data import Table, Domain\n",
        "from Orange.distance.distance import Cosine\n",
        "from Orange.widgets.unsupervised.owhierarchicalclustering import clusters_at_height\n",
        "from Orange.misc.distmatrix import DistMatrix\n",
        "from Bio import Phylo\n",
        "from io import StringIO\n",
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from Orange.data.variable import StringVariable\n",
        "from skbio import DistanceMatrix\n",
        "from skbio.tree import nj\n",
        "from typing import Dict, Tuple, List, Callable\n",
        "from tqdm import tqdm\n",
        "import sklearn.preprocessing as pp\n",
        "from scipy import sparse\n",
        "\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "HSkbQhDIG0Et"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsLoader:\n",
        "\n",
        "    \"\"\"class that load an embeddings file to perform operation on it. Base class\n",
        "     for multiple operations such as matrix similarity operations.\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, filename : str):\n",
        "\n",
        "        self.file = filename\n",
        "        self.embeddings = {}\n",
        "\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            with open(self.file, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "                \n",
        "            for line in lines[1:]:\n",
        "                data = line.split(\",\")\n",
        "                self.embeddings[data[0]] = torch.FloatTensor(list(map(float, data[1:])))\n",
        "\n",
        "        except IOError as e:\n",
        "            raise IOError(f\"No file {self.file}\")"
      ],
      "metadata": {
        "id": "F9r4YQQI9kpr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Solver"
      ],
      "metadata": {
        "id": "6a4--t_QLVl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLUSTER_THRESOLD = 0.85\n",
        "GROUP_BY = \"first superclass\"\n",
        "MYSTERY = \"TOGUESS\"\n",
        "SIM_THRESOLD = 0.3\n",
        "\n",
        "def left_join(complete_table, supp_info_table, key: str = \"embeddings\") -> Table:\n",
        "    \"\"\"add all <b> metas </b> column from supp_info_table to complete_table using key as joint\n",
        "    \"\"\"\n",
        "    assert key in list(map(lambda x : x.name, supp_info_table.domain.metas)), \"embeddings name not present in additional data\"\n",
        "    # assert len(complete_table) == len(supp_info_table), \"table don't contain the same number of line\"\n",
        "    print(len(complete_table), len(supp_info_table))\n",
        "    name_supp_data = [i.name for i in chain(supp_info_table.domain.metas, \n",
        "                                            supp_info_table.domain.variables, \n",
        "                                            supp_info_table.attributes) if i.name != key]\n",
        "                                            \n",
        "    supp_list_list = [[] for i in range(len(name_supp_data))]\n",
        "\n",
        "    for s in complete_table:\n",
        "        done = False\n",
        "        for d in supp_info_table:\n",
        "            if s[key] == d[key]:\n",
        "                for i, name in enumerate(name_supp_data):\n",
        "                    supp_list_list[i].append(d[name])\n",
        "                done = True\n",
        "                break\n",
        "        if not done:\n",
        "            for i, name in enumerate(name_supp_data):\n",
        "                supp_list_list[i].append(\"?\")\n",
        "\n",
        "    for i, name in enumerate(name_supp_data):\n",
        "        # print(f\"adding {name}\")\n",
        "        complete_table = complete_table.add_column(StringVariable(name), supp_list_list[i])\n",
        "\n",
        "    return complete_table\n",
        "\n",
        "def parent_of_mystery(cluster):\n",
        "    res = None\n",
        "    for branch in cluster.branches:\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == MYSTERY:\n",
        "                return cluster\n",
        "        else: \n",
        "            res = parent_of_mystery(branch)\n",
        "            if res is not None:\n",
        "                return res\n",
        "    return None\n",
        "    \n",
        "def first_child(root):\n",
        "    if root.is_leaf:\n",
        "        return root\n",
        "    else:\n",
        "        return first_child(root.branches[0])\n",
        "\n",
        "\n",
        "def closest_to(cluster, mystery_index):\n",
        "    if len(cluster.branches) == 1:\n",
        "        return None\n",
        "\n",
        "    next = False\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        if next:\n",
        "            return first_child(branch)\n",
        "\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                if i == 0:\n",
        "                    next = True\n",
        "                else:\n",
        "                    return first_child(cluster.branches[i-1])\n",
        "\n",
        "def add_to_list(cluster, list_to_add_to):\n",
        "    \"\"\" decompose a cluster tree by adding the index of all children in the list\n",
        "    \"\"\"\n",
        "    if cluster.is_leaf:\n",
        "        list_to_add_to.append(cluster.value.index)\n",
        "\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        add_to_list(branch, list_to_add_to)\n",
        "\n",
        "def compute(lst, tips):\n",
        "    # return max(lst,key=lst.count)\n",
        "    weighted_lst = {elem: 0 for elem in set(lst)}\n",
        "    for elem in lst:\n",
        "        if elem in tips:\n",
        "            weighted_lst[elem] += 3\n",
        "        else:\n",
        "            weighted_lst[elem] += 1\n",
        "\n",
        "    most_common = sorted([(key, elem) for key, elem in weighted_lst.items()], key = lambda x : x[1], reverse = True)\n",
        "    # print(most_common)\n",
        "    return most_common\n",
        "\n",
        "def Orange_tree_to_newick(root):\n",
        "\n",
        "    if root.is_leaf:\n",
        "        return str(root.value.index)  +  \":\" + str(root.value.height)\n",
        "\n",
        "    concat = \"(\"\n",
        "    for branch in root.branches:\n",
        "\n",
        "        concat += Orange_tree_to_newick(branch) + \",\"\n",
        "\n",
        "    concat = concat[:-1] + \")\" +  \":\" + str(root.value.height)\n",
        "    return concat\n",
        "\n",
        "def biotree_to_Orange_tree(tree):\n",
        "\n",
        "    def find_min_max(tree):\n",
        "        if tree.is_terminal():\n",
        "            return tree.branch_length\n",
        "        else:\n",
        "            maxi = -1000\n",
        "            for cla in tree:\n",
        "                max_depth = find_min_max(cla)\n",
        "                if max_depth > maxi:\n",
        "                    maxi = max_depth\n",
        "\n",
        "            return maxi + (tree.branch_length or 0)\n",
        "\n",
        "    max_depth = find_min_max(tree.root)\n",
        "\n",
        "    def recur_parse(root, acc, depth):\n",
        "        if root.is_terminal():\n",
        "            val = root.name\n",
        "            leaf = Tree(SingletonData(range = range(len(acc), len(acc)+1), \n",
        "                                 height = 0, \n",
        "                                 index = val), ())\n",
        "            acc.append(leaf)\n",
        "            return leaf\n",
        "\n",
        "        else:\n",
        "            current_depth = depth - (root.branch_length or 0)\n",
        "            list_cla = []\n",
        "            for cla in root:\n",
        "                sub_tree = recur_parse(cla, acc, current_depth)\n",
        "                list_cla.append(sub_tree)\n",
        "            node = Tree(ClusterData(range = range(list_cla[0]._Tree__value.range.start, list_cla[-1]._Tree__value.range.stop),\n",
        "                               height = current_depth), tuple(list_cla))\n",
        "            return node\n",
        "\n",
        "    orange_tree = recur_parse(tree.root, [], max_depth)\n",
        "    return orange_tree, max_depth\n",
        "\n",
        "def reroot_tree(tree):\n",
        "    newick_tree = Orange_tree_to_newick(tree)\n",
        "    tree = Phylo.read(StringIO(newick_tree), \"newick\")\n",
        "    tree.root_with_outgroup(tree.root.find_clades(\"NULL\"))\n",
        "    return biotree_to_Orange_tree(tree)\n",
        "\n",
        "def njt(table, key : str):\n",
        "\n",
        "    embeddings = {}\n",
        "    for line in table:\n",
        "        embeddings[str(line[key].value)] = list(line.attributes()) \n",
        "        \n",
        "\n",
        "    ids = list(map(lambda x : x.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"'\", \"_\"), embeddings.keys()))\n",
        "    data = np.array([item for item in embeddings.values()])\n",
        "    \n",
        "    cos_A = pairwise_distances(data, metric=\"cosine\")\n",
        "    \n",
        "    def constructor(x):\n",
        "        biotree = Phylo.read( StringIO(x), \"newick\")\n",
        "        otree, _ = biotree_to_Orange_tree(biotree)\n",
        "        return otree\n",
        "\n",
        "    dm = DistanceMatrix(cos_A, ids)\n",
        "    tree = nj(dm, result_constructor = constructor)\n",
        "\n",
        "    return tree\n",
        "\n",
        "\n",
        "\n",
        "def clusterize(table : Table, thresold, key = \"embeddings\") -> Table:\n",
        "    \"\"\"clusterize a Oranga Table based on the height of THRESOLD\n",
        "    \"\"\"\n",
        "\n",
        "    root = njt(table, key)\n",
        "    root, max_depth = reroot_tree(root)\n",
        "\n",
        "    parent_cluster = parent_of_mystery(root)\n",
        "    if thresold is None:\n",
        "        thresold = parent_cluster.value.height\n",
        "\n",
        "    cluster_tree = clusters_at_height(root, thresold)\n",
        "\n",
        "    list_cluster = {}\n",
        "    closest = None\n",
        "    mystery_len_cluster = -1\n",
        "    for i, cluster in enumerate(cluster_tree):\n",
        "        cluster_name = 'C' + str(i) \n",
        "\n",
        "        current = []\n",
        "        add_to_list(cluster, current)\n",
        "        if MYSTERY in current: \n",
        "            mystery_len_cluster = len(current)\n",
        "            closest = closest_to(parent_cluster, MYSTERY)\n",
        "\n",
        "        for item in current:\n",
        "            list_cluster[item] = cluster_name\n",
        "        # print(cluster_name, list(map(lambda x: table[x][\"embeddings\"].value, current)))\n",
        "\n",
        "    list_vocab = [line[key].value.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"'\", \"_\") for line in table]\n",
        "    table = table.add_column(StringVariable(\"Cluster\"), [list_cluster[i] if i in list_cluster.keys() else \"?\" for i in list_vocab])\n",
        "\n",
        "    return table, closest.value.index, thresold, len(cluster_tree)\n",
        "\n",
        "from typing import List\n",
        "def one_pass(table, toguess_table, keep_cluster_line : bool = False, cluster_thresold : float = CLUSTER_THRESOLD, sim_thresold : float = SIM_THRESOLD, tips : List[str] = []):\n",
        "    assert GROUP_BY in list(map(lambda x: x.name, chain(table.domain.metas, \n",
        "                                                        table.domain.variables, \n",
        "                                                        table.domain.attributes))), \"Group by not in the Table !\"\n",
        "    supp_data = {\n",
        "        \"sim_thresold\"       : sim_thresold,\n",
        "        \"keep_cluster_line\"  : keep_cluster_line,\n",
        "    }\n",
        "\n",
        "    supp_data[\"format_at_beginning\"] = (len(table), \"x\", len(table.domain.attributes))\n",
        "    table, closest, thresold, nb_cluster = clusterize(table, cluster_thresold)\n",
        "    supp_data[\"cluster_thresold\"]    = thresold\n",
        "    supp_data[\"closest_to_myster\"]   = closest # table[][\"embeddings\"].value if closest is not True else None,\n",
        "    supp_data[\"number_of_cluster\"]   = nb_cluster\n",
        "    #===========================================================================\n",
        "    # Cluster split\n",
        "    toguess_cluster = [d[\"Cluster\"] for d in table if d[\"embeddings\"] == MYSTERY][0]\n",
        "\n",
        "    in_cluster_table  = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value == toguess_cluster])\n",
        "    out_cluster_table = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value != toguess_cluster])\n",
        "    #===========================================================================\n",
        "    # Group by computation\n",
        "    supp_data[\"cluster_size\"] = len(in_cluster_table)\n",
        "    if len(in_cluster_table) <= 1: return [], supp_data\n",
        "    \n",
        "    main_superclass_count_list = compute([row[GROUP_BY].value for row in in_cluster_table], tips)\n",
        "    #equality case with \"?\", take the second\n",
        "    ind = 1 if main_superclass_count_list[0][0] == \"?\" and len(main_superclass_count_list) > 1 else 0\n",
        "    main_superclass = main_superclass_count_list[ind][0]\n",
        "    supp_data[\"cluster_name\"] = main_superclass\n",
        "\n",
        "    nb_dimension = len(list(in_cluster_table.domain.attributes))\n",
        "    average_cluster = Table.from_list(in_cluster_table.domain, [\n",
        "        [sum([line[i] for line in in_cluster_table]) / nb_dimension  for i in in_cluster_table.domain.attributes] + [\"cluster_average\"]\n",
        "    ])\n",
        "\n",
        "    # main_superclass_table = Table.from_list(superclass_embeddings.domain, [i for i in superclass_embeddings if i[\"embeddings\"] == main_superclass])\n",
        "    main_superclass_table = Table.concatenate([in_cluster_table, Table.from_table(in_cluster_table.domain, average_cluster)])\n",
        "    #===========================================================================\n",
        "    # thresold computation\n",
        "    to_copy_row_instance = [d for d in main_superclass_table if d[\"embeddings\"] == MYSTERY][0]\n",
        "    to_copy = list(to_copy_row_instance.attributes())\n",
        "\n",
        "    to_compare_row_instance = [d for d in main_superclass_table if d[\"Cluster\"] == \"?\"][0]\n",
        "    to_compare = list(to_compare_row_instance.attributes())\n",
        "\n",
        "    dead_row = [k for k, (i, j) in enumerate(zip(to_copy, to_compare)) if abs(i - j) <= sim_thresold]\n",
        "    supp_data[\"removed_col\"] = len(dead_row) \n",
        "    #===========================================================================\n",
        "    # reconstruct the table filtering dead row and cluster. Remove used cluster row if \n",
        "    # keep_cluster_line is set to False\n",
        "    new_domain = Domain(attributes = [i for i in out_cluster_table.domain.attributes if int(i.name) not in dead_row], \n",
        "                        metas      = [i for i in out_cluster_table.domain.metas if i.name != \"Cluster\"])\n",
        "\n",
        "    # do the same on the data\n",
        "    data_attr, data_meta = [], []\n",
        "    whole_data = list(out_cluster_table) + list(toguess_table)\n",
        "    if keep_cluster_line: whole_data += list(in_cluster_table)\n",
        "\n",
        "    for rowinstance in whole_data:\n",
        "        data_attr.append([rowinstance[k] for k, i in enumerate(out_cluster_table.domain.attributes) if int(i.name) not in dead_row])\n",
        "        # data_attr.append([rowinstance[k] for k, i in enumerate(out_cluster_table.domain.attributes)])\n",
        "        data_meta.append([rowinstance.metas[k] for k, i in enumerate(out_cluster_table.domain.metas) if i.name != \"Cluster\"])\n",
        "\n",
        "\n",
        "    return Table.from_numpy(new_domain, X = data_attr, metas = data_meta), supp_data\n",
        "\n",
        "\n",
        "def standardize_first(table):\n",
        "    values = table[0]\n",
        "    mean = np.mean(values)\n",
        "    std  = np.std(values)\n",
        "\n",
        "    for v in range(len(values)):\n",
        "        values[v] = (values[v] - mean) / std\n",
        "\n",
        "    return Table.from_numpy(table.domain, [values], None, table.metas)"
      ],
      "metadata": {
        "id": "nPhqx45tbDSE"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mystery(complete_table, mystery, cluster_thresold_lambda, sim_thresold_lambda, tips):\n",
        "\n",
        "    toguess_table = Table.from_numpy(complete_table.domain, [np.array(mystery)], Y = None, metas = np.char.asarray([[MYSTERY, \"?\", \"?\"]]))\n",
        "    # toguess_table = standardize_first(toguess_table)\n",
        "\n",
        "    null_table = Table.from_numpy(complete_table.domain, [np.array([1 for i in range(len(complete_table.domain.attributes))])], Y = None, metas = np.char.asarray([[\"NULL\", \"?\", \"?\"]]))\n",
        "\n",
        "    table = Table.concatenate([complete_table, toguess_table, null_table])\n",
        "    old_table = table\n",
        "\n",
        "    advancement = []\n",
        "    for i in range(5):\n",
        "        old_table = table\n",
        "        table, data = one_pass(table, toguess_table,\n",
        "                                      keep_cluster_line = False, \n",
        "                                      cluster_thresold  = cluster_thresold_lambda(i), \n",
        "                                      sim_thresold      = sim_thresold_lambda(i),\n",
        "                                      tips = tips)\n",
        "        advancement.append(data)\n",
        "\n",
        "        if len(table) <= 1 or data[\"cluster_size\"] < 10:\n",
        "            break\n",
        "    return advancement\n",
        "\n",
        "            # print(\"no result, trying to upper cluster thresold\")\n",
        "            # current_cluster_thresold = 0.55 + 0.05\n",
        "            # while current_cluster_thresold < 1 and len(current_table) == 0:\n",
        "            #     current_table, data = one_pass(old_table, keep_cluster_line = False, cluster_thresold = current_cluster_thresold, sim_thresold = 0.3 + 0.05 * i)\n",
        "            #     print(data)\n",
        "            #     current_cluster_thresold += 0.05\n",
        "            # if len(current_table) == 0:\n",
        "            #     print(\"no suitable thresold...\")\n",
        "            #     break\n",
        "            # print(\"find a suitable thresold, resuming\")"
      ],
      "metadata": {
        "id": "BnjjnjQuFJxe"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generic_table = Table(\"/content/Ayoub-average.csv\")\n",
        "supp_info_table = Table(\"/content/class_map_imagenet.csv\")\n",
        "generic_table = left_join(generic_table, supp_info_table)\n",
        "\n",
        "print(len(generic_table))\n",
        "\n",
        "# superclass_embeddings = Table(\"/content/custom-wikipedia2vec-300_superclass.csv\")"
      ],
      "metadata": {
        "id": "g_uIdCXyw6tS",
        "outputId": "0b630b87-fe69-4099-869a-13c6170f19d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "996 999\n",
            "996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myster_file = EmbeddingsLoader(\"/content/mystery.csv\")"
      ],
      "metadata": {
        "id": "nnW8xIgJThWR"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_result(list_dict):\n",
        "    superclass_list = []\n",
        "    for dic in list_dict:\n",
        "        if type(dic) == type(dict()) and \"cluster_name\" in dic.keys():\n",
        "            superclass_list.append(f\"{dic['cluster_name']}[{round(dic['cluster_size'] / len(generic_table) * 100, 1)}%]({dic['closest_to_myster']})\")\n",
        "    \n",
        "    return superclass_list\n",
        "\n",
        "# cluster_thresold_lambda = lambda x : 0.30 + 0.20 * x\n",
        "cluster_thresold_lambda     = lambda x : None\n",
        "sim_thresold_lambda     = lambda x : 0.3\n",
        "\n",
        "tips = [[\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"monotreme\"],\n",
        "        [\"monotreme\"],\n",
        "        [\"monotreme\"],\n",
        "        [\"cat\"],\n",
        "        [\"rodent\"],\n",
        "        [\"dog\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"],\n",
        "        [\"bear\"]]\n",
        "\n",
        "for k, (i, embeddings) in enumerate(myster_file.embeddings.items()):\n",
        "\n",
        "    result = solve_mystery(generic_table, embeddings, cluster_thresold_lambda, sim_thresold_lambda, tips[k])\n",
        "    print(f\"{' + '.join(format_result(result)): <80}\\t\\t{result}\")\n"
      ],
      "metadata": {
        "id": "AgI9x2O0Pkv4",
        "outputId": "4166d5aa-77c3-442f-bcbd-913dcd99deea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 300), 'cluster_thresold': 19.97935799999999, 'closest_to_myster': 'tabby', 'number_of_cluster': 132, 'cluster_size': 1}]\n",
            "                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 300), 'cluster_thresold': 17.888846000000008, 'closest_to_myster': 'muzzle', 'number_of_cluster': 596, 'cluster_size': 1}]\n",
            "                                                                                \t\t[{'sim_thresold': 0.3, 'keep_cluster_line': False, 'format_at_beginning': (998, 'x', 300), 'cluster_thresold': 17.892037999999996, 'closest_to_myster': 'muzzle', 'number_of_cluster': 594, 'cluster_size': 1}]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-235-e4c6e581fb27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyster_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_mystery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_thresold_lambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_thresold_lambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{' + '.join(format_result(result)): <80}\\t\\t{result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-106-98c9058a9ce6>\u001b[0m in \u001b[0;36msolve_mystery\u001b[0;34m(complete_table, mystery, cluster_thresold_lambda, sim_thresold_lambda, tips)\u001b[0m\n\u001b[1;32m     16\u001b[0m                                       \u001b[0mcluster_thresold\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcluster_thresold_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                       \u001b[0msim_thresold\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0msim_thresold_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                       tips = tips)\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0madvancement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-230-ab6c66144402>\u001b[0m in \u001b[0;36mone_pass\u001b[0;34m(table, toguess_table, keep_cluster_line, cluster_thresold, sim_thresold, tips)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0min_cluster_table\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Cluster\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtoguess_cluster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mout_cluster_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Cluster\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtoguess_cluster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;31m#===========================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# Group by computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/Orange/data/table.py\u001b[0m in \u001b[0;36mfrom_list\u001b[0;34m(cls, domain, rows, weights)\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m                 \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/Orange/data/instance.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mn_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_metas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         return [self[i].value if i < n_self else self[n_self - i - 1].value\n\u001b[0;32m---> 89\u001b[0;31m                 for i in range(n_self + n_metas)]\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/Orange/data/instance.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mn_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_metas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         return [self[i].value if i < n_self else self[n_self - i - 1].value\n\u001b[0;32m---> 89\u001b[0;31m                 for i in range(n_self + n_metas)]\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/Orange/data/variable.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_discrete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mUnknown\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7YVJ5THVguaG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}