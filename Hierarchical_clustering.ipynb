{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hierarchical clustering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZp0hUVU+0PLnVsA/a386I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taedriel/ZSL-v2/blob/wordEmbedding/Hierarchical_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install orange3 python-louvain networkx --quiet --upgrade"
      ],
      "metadata": {
        "id": "-nHn1AH78gzp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import community.community_louvain as community\n",
        "from Orange.clustering.hierarchical import dist_matrix_linkage, tree_from_linkage, data_clustering, leaves, WEIGHTED\n",
        "from Orange.data import Table, Domain\n",
        "from Orange.distance.distance import Cosine\n",
        "from Orange.widgets.unsupervised.owhierarchicalclustering import clusters_at_height\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from Orange.data.variable import StringVariable"
      ],
      "metadata": {
        "id": "HSkbQhDIG0Et"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsLoader:\n",
        "\n",
        "    \"\"\"class that load an embeddings file to perform operation on it. Base class\n",
        "     for multiple operations such as matrix similarity operations.\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, filename : str):\n",
        "\n",
        "        self.file = filename\n",
        "        self.embeddings = {}\n",
        "\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            with open(self.file, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "                \n",
        "            for line in lines[1:]:\n",
        "                data = line.split(\",\")\n",
        "                self.embeddings[data[0]] = torch.FloatTensor(list(map(float, data[1:])))\n",
        "\n",
        "        except IOError as e:\n",
        "            raise IOError(f\"No file {self.file}\")\n"
      ],
      "metadata": {
        "id": "F9r4YQQI9kpr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Solver"
      ],
      "metadata": {
        "id": "6a4--t_QLVl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLUSTER_THRESOLD = 0.85\n",
        "GROUP_BY = \"first superclass\"\n",
        "MYSTERY = \"TOGUESS\"\n",
        "SIM_THRESOLD = 0.3\n",
        "\n",
        "def left_join(complete_table, supp_info_table, key: str = \"embeddings\") -> Table:\n",
        "    \"\"\"add all <b> metas </b> column from supp_info_table to complete_table using key as joint\n",
        "    \"\"\"\n",
        "    assert key in list(map(lambda x : x.name, supp_info_table.domain.metas)), \"embeddings name not present in additional data\"\n",
        "    # assert len(complete_table) == len(supp_info_table), \"table don't contain the same number of line\"\n",
        "\n",
        "    name_supp_data = [i.name for i in chain(supp_info_table.domain.metas, \n",
        "                                            supp_info_table.domain.variables, \n",
        "                                            supp_info_table.attributes) if i.name != key]\n",
        "                                            \n",
        "    supp_list_list = [[] for i in range(len(name_supp_data))]\n",
        "\n",
        "    for s in complete_table:\n",
        "        done = False\n",
        "        for d in supp_info_table:\n",
        "            if s[key] == d[key]:\n",
        "                for i, name in enumerate(name_supp_data):\n",
        "                    supp_list_list[i].append(d[name])\n",
        "                done = True\n",
        "                break\n",
        "        if not done:\n",
        "            for i, name in enumerate(name_supp_data):\n",
        "                supp_list_list[i].append(\"?\")\n",
        "\n",
        "    for i, name in enumerate(name_supp_data):\n",
        "        # print(f\"adding {name}\")\n",
        "        complete_table = complete_table.add_column(StringVariable(name), supp_list_list[i])\n",
        "\n",
        "    return complete_table\n",
        "\n",
        "def parent_of_mystery(cluster, mystery_index):\n",
        "    res = None\n",
        "    for branch in cluster.branches:\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                return cluster\n",
        "        else: \n",
        "            res = parent_of_mystery(branch, mystery_index)\n",
        "            if res is not None:\n",
        "                return res\n",
        "    \n",
        "def first_child(root):\n",
        "    if root.is_leaf:\n",
        "        return root\n",
        "    else:\n",
        "        return first_child(root.branches[0])\n",
        "\n",
        "\n",
        "def closest_to(cluster, mystery_index):\n",
        "    if len(cluster.branches) == 1:\n",
        "        return None\n",
        "\n",
        "    next = False\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        if next:\n",
        "            return first_child(branch)\n",
        "\n",
        "        if branch.is_leaf:\n",
        "            if branch.value.index == mystery_index:\n",
        "                if i == 0:\n",
        "                    next = True\n",
        "                else:\n",
        "                    return first_child(cluster.branches[i-1])\n",
        "\n",
        "def add_to_list(cluster, list_to_add_to):\n",
        "    \"\"\" decompose a cluster tree by adding the index of all children in the list\n",
        "    \"\"\"\n",
        "    if cluster.is_leaf:\n",
        "        list_to_add_to.append(cluster.value.index)\n",
        "\n",
        "    for i, branch in enumerate(cluster.branches):\n",
        "        add_to_list(branch, list_to_add_to)\n",
        "\n",
        "def clusterize(table : Table, thresold, key = \"embeddings\") -> Table:\n",
        "    \"\"\"clusterize a Oranga Table based on the height of THRESOLD\n",
        "    \"\"\"\n",
        "    for i in table[-1::-1]:\n",
        "        if i[key] == MYSTERY:\n",
        "            mystery_index = table.index(i)\n",
        "            break\n",
        "\n",
        "    root = data_clustering(table, distance=Cosine, linkage=WEIGHTED)\n",
        "    parent_cluster = parent_of_mystery(root, mystery_index)\n",
        "    if thresold is None:\n",
        "        thresold = min(parent_cluster.value.height + 0.001, 1)\n",
        "\n",
        "    cluster_tree = clusters_at_height(root, thresold)\n",
        "\n",
        "    list_cluster = {}\n",
        "    closest = None\n",
        "    mystery_len_cluster = -1\n",
        "    for i, cluster in enumerate(cluster_tree):\n",
        "        cluster_name     = 'C' + str(i) \n",
        "\n",
        "        current = []\n",
        "        add_to_list(cluster, current)\n",
        "        if mystery_index in current: \n",
        "            mystery_len_cluster = len(current)\n",
        "            closest = closest_to(parent_cluster, mystery_index)\n",
        "\n",
        "        for item_index in current:\n",
        "            list_cluster[item_index] = cluster_name\n",
        "        # print(cluster_name, list(map(lambda x: table[x][\"embeddings\"].value, current)))\n",
        "\n",
        "    # print(f\"last cluster: {i} ({mystery_len_cluster})\")\n",
        "    table = table.add_column(StringVariable(\"Cluster\"), [list_cluster[i] for i in range(len(table))])\n",
        "\n",
        "    return table, closest.value.index, thresold, i\n",
        "\n",
        "def compute(lst):\n",
        "    # return max(lst,key=lst.count)\n",
        "    counter = Counter(lst)\n",
        "    return counter.most_common(len(lst))\n",
        "\n",
        "def one_pass(table, toguess_table, keep_cluster_line : bool = False, cluster_thresold : float = CLUSTER_THRESOLD, sim_thresold : float = SIM_THRESOLD):\n",
        "    assert GROUP_BY in list(map(lambda x: x.name, chain(table.domain.metas, \n",
        "                                                        table.domain.variables, \n",
        "                                                        table.domain.attributes))), \"Group by not in the Table !\"\n",
        "    \n",
        "    format = (len(table), \"x\", len(table.domain.attributes))\n",
        "    table, closest, thresold, nb_cluster = clusterize(table, cluster_thresold)\n",
        "    #===========================================================================\n",
        "    # Cluster split\n",
        "    toguess_cluster = [d[\"Cluster\"] for d in table if d[\"embeddings\"] == MYSTERY][0]\n",
        "\n",
        "    in_cluster_table  = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value == toguess_cluster])\n",
        "    out_cluster_table = Table.from_list(table.domain, [d for d in table if d[\"Cluster\"].value != toguess_cluster])\n",
        "    #===========================================================================\n",
        "    # Group by computation\n",
        "    main_superclass_count_list = compute([row[GROUP_BY].value for row in in_cluster_table])\n",
        "    #equality case with \"?\", take the second\n",
        "    ind = 1 if main_superclass_count_list[0][0] == \"?\" and len(main_superclass_count_list) > 1 else 0\n",
        "\n",
        "    main_superclass = main_superclass_count_list[ind][0]\n",
        "    main_superclass_table = Table.from_list(superclass_embeddings.domain, \n",
        "                                            [i for i in superclass_embeddings if i[\"embeddings\"] == main_superclass])\n",
        "    if len(main_superclass_table) == 0: return [], \"cluster is empty\"\n",
        "\n",
        "    main_superclass_table = Table.concatenate([in_cluster_table, Table.from_table(out_cluster_table.domain, \n",
        "                                                                                  main_superclass_table)])\n",
        "    #===========================================================================\n",
        "    # thresold computation\n",
        "    to_copy_row_instance = [d for d in main_superclass_table if d[\"embeddings\"] == MYSTERY][0]\n",
        "    to_copy = list(to_copy_row_instance.attributes())\n",
        "\n",
        "    to_compare_row_instance = [d for d in main_superclass_table if d[\"Cluster\"] == \"?\"][0]\n",
        "    to_compare = list(to_compare_row_instance.attributes())\n",
        "\n",
        "    dead_row = [k for k, (i, j) in enumerate(zip(to_copy, to_compare)) if abs(i - j) <= sim_thresold]\n",
        "    #===========================================================================\n",
        "    # reconstruct the table filtering dead row and cluster. Remove used cluster row if \n",
        "    # keep_cluster_line is set to False\n",
        "    new_domain = Domain(attributes = [i for i in out_cluster_table.domain.attributes if int(i.name) not in dead_row], \n",
        "                        metas      = [i for i in out_cluster_table.domain.metas if i.name != \"Cluster\"])\n",
        "\n",
        "    # do the same on the data\n",
        "    data_attr, data_meta = [], []\n",
        "    whole_data = list(out_cluster_table) + list(toguess_table)\n",
        "    if keep_cluster_line: whole_data += list(in_cluster_table)\n",
        "\n",
        "    for rowinstance in whole_data:\n",
        "        data_attr.append([rowinstance[k] for k, i in enumerate(out_cluster_table.domain.attributes) if int(i.name) not in dead_row])\n",
        "        data_meta.append([rowinstance.metas[k] for k, i in enumerate(out_cluster_table.domain.metas) if i.name != \"Cluster\"])\n",
        "\n",
        "    return Table.from_numpy(new_domain, X = data_attr, metas = data_meta), \\\n",
        "        { \"cluster\" : {\n",
        "                \"name\" : main_superclass,\n",
        "                \"size\" : len(in_cluster_table) - 1,\n",
        "                \"thresold\": thresold,\n",
        "                \"closest_to_myster\" : table[closest][\"embeddings\"].value if closest is not True else None\n",
        "            },\n",
        "            \"number_of_cluster\" : nb_cluster,\n",
        "           \"format_at_beginning\": format,\n",
        "           \"keep_cluster_line\"  : keep_cluster_line,\n",
        "           \"sim_thresold\"       : sim_thresold,\n",
        "           \"removed_col\"        : len(dead_row) \n",
        "        }\n",
        "\n",
        "def standardize_first(table):\n",
        "    values = table[0]\n",
        "    mean = np.mean(values)\n",
        "    std  = np.std(values)\n",
        "\n",
        "    for v in range(len(values)):\n",
        "        values[v] = (values[v] - mean) / std\n",
        "\n",
        "    return Table.from_numpy(table.domain, [values], None, table.metas)"
      ],
      "metadata": {
        "id": "nPhqx45tbDSE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generic_table = Table(\"/content/imagenet-wikipedia2vec-300.csv\")\n",
        "supp_info_table = Table(\"/content/class_map_imagenet.csv\")\n",
        "generic_table = left_join(generic_table, supp_info_table)\n",
        "\n",
        "superclass_embeddings = Table(\"/content/custom-wikipedia2vec-300_superclass.csv\")"
      ],
      "metadata": {
        "id": "g_uIdCXyw6tS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mystery(complete_table, mystery, cluster_thresold_lambda, sim_thresold_lambda):\n",
        "\n",
        "    toguess_table = Table.from_numpy(complete_table.domain, [np.array(mystery)], Y = None, metas = np.char.asarray([[MYSTERY, \"?\", \"?\"]]))\n",
        "    toguess_table = standardize_first(toguess_table)\n",
        "\n",
        "    table = Table.concatenate([complete_table, toguess_table])\n",
        "    old_table = table\n",
        "\n",
        "    advancement = []\n",
        "    for i in range(5):\n",
        "        old_table = table\n",
        "        table, data = one_pass(table, toguess_table,\n",
        "                                      keep_cluster_line = False, \n",
        "                                      cluster_thresold  = cluster_thresold_lambda(i), \n",
        "                                      sim_thresold      = sim_thresold_lambda(i))\n",
        "        advancement.append(data)\n",
        "\n",
        "        if len(table) <= 1:\n",
        "            break\n",
        "    return advancement\n",
        "\n",
        "            # print(\"no result, trying to upper cluster thresold\")\n",
        "            # current_cluster_thresold = 0.55 + 0.05\n",
        "            # while current_cluster_thresold < 1 and len(current_table) == 0:\n",
        "            #     current_table, data = one_pass(old_table, keep_cluster_line = False, cluster_thresold = current_cluster_thresold, sim_thresold = 0.3 + 0.05 * i)\n",
        "            #     print(data)\n",
        "            #     current_cluster_thresold += 0.05\n",
        "            # if len(current_table) == 0:\n",
        "            #     print(\"no suitable thresold...\")\n",
        "            #     break\n",
        "            # print(\"find a suitable thresold, resuming\")"
      ],
      "metadata": {
        "id": "BnjjnjQuFJxe"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myster_file = EmbeddingsLoader(\"/content/mystery.csv\")"
      ],
      "metadata": {
        "id": "nnW8xIgJThWR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_result(list_dict):\n",
        "    superclass_list = []\n",
        "    for dic in list_dict:\n",
        "        if type(dic) == type(dict()):\n",
        "            superclass_list.append((dic[\"cluster\"][\"name\"], dic[\"cluster\"][\"closest_to_myster\"], dic[\"cluster\"][\"thresold\"]))\n",
        "    \n",
        "    return superclass_list\n",
        "\n",
        "# cluster_thresold_lambda = lambda x : 0.65 + 0.05 * x\n",
        "cluster_thresold_lambda     = lambda x : None\n",
        "sim_thresold_lambda     = lambda x : 0.1 + 0.05 * x\n",
        "\n",
        "for i, embeddings in myster_file.embeddings.items():\n",
        "\n",
        "    result = solve_mystery(generic_table, embeddings, cluster_thresold_lambda, sim_thresold_lambda)\n",
        "    print(i, *result, sep = \",\")\n"
      ],
      "metadata": {
        "id": "AgI9x2O0Pkv4",
        "outputId": "426f7178-37e6-4dba-f75d-045a032c318f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0,{'cluster': {'name': 'dog', 'size': 1, 'thresold': 0.3481095649353513, 'closest_to_myster': 'affenpinscher'}, 'number_of_cluster': 936, 'format_at_beginning': (1000, 'x', 300), 'keep_cluster_line': False, 'sim_thresold': 0.1, 'removed_col': 22},{'cluster': {'name': 'dog', 'size': 1, 'thresold': 0.30940756879306053, 'closest_to_myster': 'otterhound'}, 'number_of_cluster': 957, 'format_at_beginning': (999, 'x', 278), 'keep_cluster_line': False, 'sim_thresold': 0.15000000000000002, 'removed_col': 9},{'cluster': {'name': 'dog', 'size': 997, 'thresold': 0.9317622545442632, 'closest_to_myster': 'carbonara'}, 'number_of_cluster': 0, 'format_at_beginning': (998, 'x', 269), 'keep_cluster_line': False, 'sim_thresold': 0.2, 'removed_col': 39}\n",
            "1,{'cluster': {'name': 'dog', 'size': 6, 'thresold': 0.30113508623620966, 'closest_to_myster': 'curly-coated retriever'}, 'number_of_cluster': 966, 'format_at_beginning': (1000, 'x', 300), 'keep_cluster_line': False, 'sim_thresold': 0.1, 'removed_col': 32},{'cluster': {'name': 'dog', 'size': 1, 'thresold': 0.2799952318283736, 'closest_to_myster': 'affenpinscher'}, 'number_of_cluster': 968, 'format_at_beginning': (994, 'x', 268), 'keep_cluster_line': False, 'sim_thresold': 0.15000000000000002, 'removed_col': 14},{'cluster': {'name': 'dog', 'size': 992, 'thresold': 0.9905153424920679, 'closest_to_myster': 'Newfoundland'}, 'number_of_cluster': 0, 'format_at_beginning': (993, 'x', 255), 'keep_cluster_line': False, 'sim_thresold': 0.2, 'removed_col': 27}\n",
            "2,{'cluster': {'name': 'dog', 'size': 1, 'thresold': 0.28911812616396404, 'closest_to_myster': 'miniature pinscher'}, 'number_of_cluster': 971, 'format_at_beginning': (1000, 'x', 300), 'keep_cluster_line': False, 'sim_thresold': 0.1, 'removed_col': 18},{'cluster': {'name': 'dog', 'size': 1, 'thresold': 0.2876491199262503, 'closest_to_myster': 'affenpinscher'}, 'number_of_cluster': 966, 'format_at_beginning': (999, 'x', 282), 'keep_cluster_line': False, 'sim_thresold': 0.15000000000000002, 'removed_col': 11},cluster is empty\n",
            "4,{'cluster': {'name': 'monotreme', 'size': 1, 'thresold': 0.3241293333761378, 'closest_to_myster': 'platypus'}, 'number_of_cluster': 954, 'format_at_beginning': (1000, 'x', 300), 'keep_cluster_line': False, 'sim_thresold': 0.1, 'removed_col': 29},{'cluster': {'name': 'snake', 'size': 1, 'thresold': 0.32924463543277016, 'closest_to_myster': 'water snake'}, 'number_of_cluster': 943, 'format_at_beginning': (999, 'x', 271), 'keep_cluster_line': False, 'sim_thresold': 0.15000000000000002, 'removed_col': 29},cluster is empty\n",
            "5,{'cluster': {'name': 'monotreme', 'size': 1, 'thresold': 0.3306472144802953, 'closest_to_myster': 'platypus'}, 'number_of_cluster': 948, 'format_at_beginning': (1000, 'x', 300), 'keep_cluster_line': False, 'sim_thresold': 0.1, 'removed_col': 30},{'cluster': {'name': 'turtle', 'size': 2, 'thresold': 0.37326739750191873, 'closest_to_myster': 'mud turtle'}, 'number_of_cluster': 899, 'format_at_beginning': (999, 'x', 270), 'keep_cluster_line': False, 'sim_thresold': 0.15000000000000002, 'removed_col': 34},{'cluster': {'name': 'dog', 'size': 996, 'thresold': 0.9668980424294803, 'closest_to_myster': 'Leonberg'}, 'number_of_cluster': 0, 'format_at_beginning': (997, 'x', 239), 'keep_cluster_line': False, 'sim_thresold': 0.2, 'removed_col': 37}\n",
            "6,{'cluster': {'name': 'monotreme', 'size': 1, 'thresold': 0.2994726314997832, 'closest_to_myster': 'platypus'}, 'number_of_cluster': 966, 'format_at_beginning': (1000, 'x', 300), 'keep_cluster_line': False, 'sim_thresold': 0.1, 'removed_col': 26},{'cluster': {'name': 'lizard', 'size': 1, 'thresold': 0.3545986517862454, 'closest_to_myster': 'frilled lizard'}, 'number_of_cluster': 920, 'format_at_beginning': (999, 'x', 274), 'keep_cluster_line': False, 'sim_thresold': 0.15000000000000002, 'removed_col': 34},cluster is empty\n",
            "7,{'cluster': {'name': 'dog', 'size': 2, 'thresold': 0.4009334785341114, 'closest_to_myster': 'affenpinscher'}, 'number_of_cluster': 859, 'format_at_beginning': (1000, 'x', 300), 'keep_cluster_line': False, 'sim_thresold': 0.1, 'removed_col': 30},{'cluster': {'name': 'snake', 'size': 4, 'thresold': 0.3890363811454546, 'closest_to_myster': 'vine snake'}, 'number_of_cluster': 860, 'format_at_beginning': (998, 'x', 270), 'keep_cluster_line': False, 'sim_thresold': 0.15000000000000002, 'removed_col': 15},{'cluster': {'name': 'outdoor scene', 'size': 1, 'thresold': 0.8887584150122354, 'closest_to_myster': 'alp'}, 'number_of_cluster': 1, 'format_at_beginning': (994, 'x', 256), 'keep_cluster_line': False, 'sim_thresold': 0.2, 'removed_col': 26},{'cluster': {'name': 'dog', 'size': 992, 'thresold': 0.9541099964918514, 'closest_to_myster': 'abaya'}, 'number_of_cluster': 0, 'format_at_beginning': (993, 'x', 234), 'keep_cluster_line': False, 'sim_thresold': 0.25, 'removed_col': 40}\n",
            "8,{'cluster': {'name': 'rodent', 'size': 1, 'thresold': 0.32889111110530245, 'closest_to_myster': 'hamster'}, 'number_of_cluster': 949, 'format_at_beginning': (1000, 'x', 300), 'keep_cluster_line': False, 'sim_thresold': 0.1, 'removed_col': 33},{'cluster': {'name': 'dog', 'size': 1, 'thresold': 0.3607965713347089, 'closest_to_myster': 'affenpinscher'}, 'number_of_cluster': 906, 'format_at_beginning': (999, 'x', 267), 'keep_cluster_line': False, 'sim_thresold': 0.15000000000000002, 'removed_col': 30},{'cluster': {'name': 'dog', 'size': 997, 'thresold': 0.9949890773725473, 'closest_to_myster': 'web site'}, 'number_of_cluster': 0, 'format_at_beginning': (998, 'x', 240), 'keep_cluster_line': False, 'sim_thresold': 0.2, 'removed_col': 34}\n",
            "9,{'cluster': {'name': 'dog', 'size': 2, 'thresold': 0.25811464099694414, 'closest_to_myster': 'curly-coated retriever'}, 'number_of_cluster': 978, 'format_at_beginning': (1000, 'x', 300), 'keep_cluster_line': False, 'sim_thresold': 0.1, 'removed_col': 27},{'cluster': {'name': 'dog', 'size': 4, 'thresold': 0.24570057525882621, 'closest_to_myster': 'Eskimo dog'}, 'number_of_cluster': 980, 'format_at_beginning': (998, 'x', 273), 'keep_cluster_line': False, 'sim_thresold': 0.15000000000000002, 'removed_col': 9},{'cluster': {'name': 'dog', 'size': 993, 'thresold': 0.9784515420603536, 'closest_to_myster': 'Newfoundland'}, 'number_of_cluster': 0, 'format_at_beginning': (994, 'x', 264), 'keep_cluster_line': False, 'sim_thresold': 0.2, 'removed_col': 29}\n"
          ]
        }
      ]
    }
  ]
}