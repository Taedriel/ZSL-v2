{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Launcher.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSRrpCpNdkVsRMXM2o5A/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taedriel/ZSL-v2/blob/startArchiWordEmbedding/Launcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DB9CVVe2Vta"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Taedriel/ZSL-v2.git\n",
        "!cd ZSL-v2/ ; git checkout startArchiWordEmbedding; git pull\n",
        "!cd ZSL-v2/ ; pip install -r requirements.txt --quiet --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/ZSL-v2\")\n",
        "sys.path.append(\"/content/ZSL-v2/zsl\")\n",
        "\n",
        "from typing import List\n",
        "from torch import Tensor\n",
        "from Orange.data import Table\n",
        "\n",
        "import zsl"
      ],
      "metadata": {
        "id": "b-Np1knU7I-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runtime = {}\n",
        "\n",
        "def check_file_presence():\n",
        "    from os.path import exists\n",
        "\n",
        "    file_to_check = [\n",
        "        \"/content/Aroub-average.csv\",\n",
        "        \"/content/class_map_imagenet.csv\",\n",
        "        \"/content/custom-wikipedia2vec-300_superclass.csv\"\n",
        "    ]\n",
        "\n",
        "    for file in file_to_check:\n",
        "        if not exists(file):\n",
        "            raise FileNotFoundError(file)\n",
        "\n",
        "def image_to_text_embedding(image_path : str) -> List[float] or Tensor:\n",
        "    return list(range(300))\n",
        "\n",
        "def text_embedding_to_classes(embedding : List[float or Tensor]) -> List[str]:\n",
        "\n",
        "    embedding = zsl.HiCA(embedding, runtime[\"prior_knowledge_table\"], runtime[\"superclass_embeddings\"]) \\\n",
        "        .solve(lambda x : 0.25 + 0.05 * x, lambda x : 0.1 + 0.05 * x)\n",
        "\n",
        "    return embedding\n",
        "\n",
        "def classes_to_prediction(image_path : str, plausible_classes : List[str]) -> List[str]:\n",
        "    return [(\"platypus\", 0.89), (\"beaver\", 0.23)]\n",
        "\n",
        "def run_pipeline(image_path : str, intermediate_result = False):\n",
        "\n",
        "    text_embedding = image_to_text_embedding(image_path)\n",
        "\n",
        "    plausible_classes = text_embedding_to_classes(text_embedding)\n",
        "\n",
        "    return classes_to_prediction(image_path, plausible_classes)\n",
        "\n",
        "def preprocess():\n",
        "\n",
        "    generic_table = Table(\"/content/Aroub-average.csv\")\n",
        "    supp_info_table = Table(\"/content/class_map_imagenet.csv\")\n",
        "\n",
        "    runtime[\"prior_knowledge_table\"] = zsl.HiCA.left_join(generic_table, supp_info_table)\n",
        "    runtime[\"superclass_embeddings\"] = Table(\"/content/custom-wikipedia2vec-300_superclass.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    check_file_presence()\n",
        "    preprocess()\n",
        "    result, _ = run_pipeline(\"examples/002.png\", intermediate_result = False)\n",
        "\n"
      ],
      "metadata": {
        "id": "vdcKTAwQ34kT",
        "outputId": "323ebe45-47d0-4f7e-898e-1021416fffc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7c15261945ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mcheck_file_presence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"examples/002.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-7c15261945ae>\u001b[0m in \u001b[0;36mcheck_file_presence\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_to_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimage_to_text_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: /content/Aroub-average.csv"
          ]
        }
      ]
    }
  ]
}